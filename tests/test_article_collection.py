# -*- coding: utf-8 -*-
"""
çˆ†ç«æ–‡ç« æ”¶é›†æ¨¡å—æµ‹è¯•
æµ‹è¯• ArticleCollectorService å’Œç›¸å…³ API æ¥å£

åŒ…å«ï¼š
1. Mock æµ‹è¯• - ç”¨äº CI/CD ç¯å¢ƒ
2. çœŸå®ç¯å¢ƒæµ‹è¯• - ç”¨äºæœ¬åœ°è°ƒè¯•å’ŒåŠŸèƒ½éªŒè¯
"""

import pytest
import requests
import pytest_asyncio
import asyncio
from unittest.mock import AsyncMock, MagicMock, patch
from datetime import datetime

from tests.helpers.mock_data import MockData
from backend.database.models import ReferenceArticle
from backend.services.article_collector_service import ArticleCollectorService
from backend.services.playwright.collectors.base import CollectedArticle


# æµ‹è¯•åŸºç¡€ URL
BASE_URL = "http://127.0.0.1:8001"
COLLECT_API = f"{BASE_URL}/api/v1/collect"


# ==================== çœŸå®ç¯å¢ƒæµ‹è¯•é…ç½® ====================

# çœŸå®ç¯å¢ƒæµ‹è¯•çš„æœç´¢å…³é”®è¯
REAL_TEST_KEYWORD = "äººå·¥æ™ºèƒ½"

# çœŸå®ç¯å¢ƒæµ‹è¯•çš„å¹³å°é…ç½®
REAL_PLATFORMS = {
    "zhihu": {
        "name": "çŸ¥ä¹",
        "search_url": "https://www.zhihu.com/search?type=content&q=äººå·¥æ™ºèƒ½",
    },
    "toutiao": {
        "name": "ä»Šæ—¥å¤´æ¡",
        "search_url": "https://so.toutiao.com/search?enable_druid_v2=1&keyword=äººå·¥æ™ºèƒ½&dvpf=pc&source=search_subtab_switch&pd=information&action_type=search_subtab_switch&page_num=0&search_id=&from=news&cur_tab_title=news",
    }
}


# ==================== Mock æ•°æ® ====================

class MockArticleData:
    """Mock æ–‡ç« æ•°æ®ç”Ÿæˆå™¨"""

    @staticmethod
    def collected_article(platform: str = "zhihu") -> dict:
        """ç”Ÿæˆ Mock é‡‡é›†æ–‡ç« æ•°æ®"""
        import random
        return {
            "title": f"æµ‹è¯•çˆ†ç«æ–‡ç« _{random.randint(1000, 9999)}",
            "url": f"https://www.{platform}.com/article/{random.randint(10000, 99999)}",
            "content": "è¿™æ˜¯ä¸€ç¯‡æµ‹è¯•æ–‡ç« çš„æ­£æ–‡å†…å®¹ã€‚" * 20,
            "likes": random.randint(100, 5000),
            "reads": random.randint(1000, 50000),
            "comments": random.randint(10, 500),
            "author": f"æµ‹è¯•ä½œè€…_{random.randint(100, 999)}",
            "platform": platform,
            "publish_time": datetime.now().isoformat()
        }

    @staticmethod
    def collect_request() -> dict:
        """ç”Ÿæˆ Mock é‡‡é›†è¯·æ±‚æ•°æ®"""
        return {
            "keyword": "äººå·¥æ™ºèƒ½",
            "platforms": ["zhihu", "toutiao"],
            "min_likes": 100,
            "min_reads": 1000,
            "max_articles_per_platform": 5,
            "save_to_db": True,
            "sync_to_ragflow": False
        }

    @staticmethod
    def zhihu_articles(count: int = 3) -> list:
        """ç”Ÿæˆ Mock çŸ¥ä¹æ–‡ç« åˆ—è¡¨"""
        return [MockArticleData.collected_article("zhihu") for _ in range(count)]

    @staticmethod
    def toutiao_articles(count: int = 3) -> list:
        """ç”Ÿæˆ Mock å¤´æ¡æ–‡ç« åˆ—è¡¨"""
        return [MockArticleData.collected_article("toutiao") for _ in range(count)]


# ==================== çœŸå®ç¯å¢ƒæµ‹è¯•ç±» ====================

@pytest.mark.real_env
class TestRealEnvironmentCollection:
    """
    çœŸå®ç¯å¢ƒæŠ“å–æµ‹è¯•

    æ³¨æ„ï¼š
    1. è¿™ä¸ªæµ‹è¯•ç±»ä½¿ç”¨çœŸå®çš„ Playwright æµè§ˆå™¨ï¼ˆéæ— å¤´æ¨¡å¼ï¼‰
    2. ä¼šçœŸå®è®¿é—®çŸ¥ä¹å’Œå¤´æ¡ç½‘ç«™
    3. å¢åŠ äº†å»¶æ—¶ä»¥é¿å…è¢«ç½‘ç«™æ£€æµ‹ä¸ºçˆ¬è™«
    4. ä¼šæ‰“å°æŠ“å–ç»“æœåˆ°æ§åˆ¶å°

    è¿è¡Œæ–¹å¼ï¼š
        pytest tests/test_article_collection.py::TestRealEnvironmentCollection -v -s --real-env
    """

    @pytest_asyncio.fixture
    async def real_browser(self):
        """åˆ›å»ºçœŸå®æµè§ˆå™¨å®ä¾‹ï¼ˆéæ— å¤´æ¨¡å¼ï¼‰"""
        from playwright.async_api import async_playwright
        import os

        playwright = await async_playwright().start()

        # æŸ¥æ‰¾ Chrome æµè§ˆå™¨è·¯å¾„
        chrome_paths = [
            r"C:\Program Files\Google\Chrome\Application\chrome.exe",
            r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
            r"C:\Users\{}\AppData\Local\Google\Chrome\Application\chrome.exe".format(
                os.environ.get("USERNAME", "")
            ),
        ]

        executable_path = None
        for path in chrome_paths:
            if os.path.exists(path):
                executable_path = path
                print(f"\nâœ… æ‰¾åˆ° Chrome æµè§ˆå™¨: {path}")
                break

        launch_options = {
            "headless": False,  # éæ— å¤´æ¨¡å¼ï¼Œå¯ä»¥çœ‹åˆ°æµè§ˆå™¨æ“ä½œ
            "args": [
                "--start-maximized",
                "--disable-blink-features=AutomationControlled",
                "--disable-dev-shm-usage",
                "--no-sandbox",
                "--disable-web-security",
                "--disable-features=IsolateOrigins,site-per-process",
                "--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
            ],
            "slow_mo": 100,  # æ¯ä¸ªæ“ä½œå¢åŠ  100ms å»¶è¿Ÿï¼Œä¾¿äºè§‚å¯Ÿ
        }

        if executable_path:
            launch_options["executable_path"] = executable_path

        browser = await playwright.chromium.launch(**launch_options)

        yield browser, playwright

        # æ¸…ç†
        await browser.close()
        await playwright.stop()

    async def _handle_login_popup(self, page):
        """æµ‹è¯•è„šæœ¬ä¸­çš„å¼¹çª—æ£€æµ‹"""
        try:
            # 2. å¸¸è§å¼¹çª—é€‰æ‹©å™¨
            popup_selectors = [
                ".Modal-wrapper", # çŸ¥ä¹ç™»å½•å¼¹çª—
                ".login-modal", 
                ".captcha-box",
                ".sign-flow-modal", # çŸ¥ä¹ç™»å½•
                "[class*='login-modal']", # é€šç”¨ç™»å½•æ¨¡æ€æ¡†
                "[class*='LoginModal']",
                ".SignFlow", # çŸ¥ä¹
                ".Button.SignFlow-submitButton", # çŸ¥ä¹ç™»å½•æŒ‰é’®
                "iframe[src*='login']", # ç™»å½• iframe
                "#captcha-verify-image", # éªŒè¯ç 
                "div[class*='captcha']", # é€šç”¨éªŒè¯ç å®¹å™¨
                ".verify-bar-close", # éªŒè¯æ¡å…³é—­æŒ‰é’®
            ]
            
            needs_login = False
            for selector in popup_selectors:
                if await page.query_selector(selector):
                    if await page.is_visible(selector):
                        needs_login = True
                        print(f"âš ï¸ å‘ç°ç™»å½•å¼¹çª—é€‰æ‹©å™¨: {selector}")
                        break
            
            # 3. æ£€æŸ¥é¡µé¢æ–‡æœ¬
            if not needs_login:
                try:
                    title = await page.title()
                    if "ç™»å½•" in title or "å®‰å…¨éªŒè¯" in title:
                        needs_login = True
                    else:
                        js_check = """
                            () => {
                                const text = document.body.innerText;
                                const keywords = ["ç™»å½•åæŸ¥çœ‹æ›´å¤š", "è¯·ç™»å½•", "æ‰«ç ç™»å½•", "éªŒè¯ç ", "å®‰å…¨éªŒè¯", "æ³¨å†Œ/ç™»å½•", "ä¾æ¬¡ç‚¹å‡»", "æ‹–åŠ¨æ»‘å—"];
                                return keywords.some(k => text.includes(k));
                            }
                        """
                        if await page.evaluate(js_check):
                             needs_login = True
                             print("âš ï¸ é¡µé¢æ–‡æœ¬åŒ…å«ç™»å½•å…³é”®è¯")
                except Exception:
                    pass
            
            if needs_login:
                print("\n" + "!"*50)
                print("æ£€æµ‹åˆ°ç™»å½•å¼¹çª—æˆ–éªŒè¯ç ï¼")
                print("è¯·åœ¨ 45 ç§’å†…æ‰‹åŠ¨å®Œæˆç™»å½•/éªŒè¯æ“ä½œ...")
                print("!"*50 + "\n")
                
                # ç»™ç”¨æˆ· 45 ç§’æ—¶é—´æ‰‹åŠ¨æ“ä½œ
                await page.wait_for_timeout(45000)
                print("æ‰‹åŠ¨æ“ä½œæ—¶é—´ç»“æŸï¼Œç»§ç»­æ‰§è¡Œ...")
                
        except Exception as e:
            print(f"ç™»å½•æ£€æµ‹å¼‚å¸¸: {e}")

    @pytest.mark.asyncio
    async def test_zhihu_real_search(self, real_browser):
        """
        æµ‹è¯•çŸ¥ä¹çœŸå®æœç´¢

        ä¼šæ‰“å¼€çœŸå®æµè§ˆå™¨ï¼Œæœç´¢å…³é”®è¯ï¼Œå¹¶æ‰“å°ç»“æœ
        """
        browser, playwright = real_browser

        print("\n" + "=" * 60)
        print("ğŸ” å¼€å§‹çŸ¥ä¹çœŸå®ç¯å¢ƒæœç´¢æµ‹è¯•")
        print("=" * 60)

        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
        context = await browser.new_context(
            viewport={"width": 1280, "height": 800},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        )
        # é˜²æ­¢ WebDriver æ£€æµ‹
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        """)
        
        page = await context.new_page()


        try:
            # å¯¼èˆªåˆ°çŸ¥ä¹æœç´¢é¡µ
            search_url = f"https://www.zhihu.com/search?type=content&q={REAL_TEST_KEYWORD}"
            print(f"ğŸ“Œ è®¿é—® URL: {search_url}")

            await page.goto(search_url, wait_until="networkidle")
            
            # æ£€æµ‹ç™»å½•å¼¹çª—
            await self._handle_login_popup(page)

            # å¢åŠ å»¶æ—¶ï¼Œç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            print("â³ ç­‰å¾…é¡µé¢åŠ è½½...")
            await page.wait_for_timeout(3000)

            # æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹
            print("ğŸ“œ æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹...")
            for i in range(3):
                # æ£€æµ‹ç™»å½•å¼¹çª—
                await self._handle_login_popup(page)
                
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await page.wait_for_timeout(3000)  # æ¯æ¬¡æ»šåŠ¨åç­‰å¾… 3 ç§’
                print(f"   æ»šåŠ¨ {i + 1}/3 å®Œæˆ")

            # æå–æœç´¢ç»“æœ
            print("\nğŸ“ æå–æœç´¢ç»“æœ...")
            articles = []

            # è·å–æ‰€æœ‰æœç´¢ç»“æœå¡ç‰‡
            cards = await page.query_selector_all(".SearchResult-Card, .Card.SearchResult-Card")
            print(f"   æ‰¾åˆ° {len(cards)} ä¸ªæœç´¢ç»“æœå¡ç‰‡")

            for idx, card in enumerate(cards):
                try:
                    # æå–æ ‡é¢˜å’Œé“¾æ¥
                    title_elem = await card.query_selector("h2.ContentItem-title a, .ContentItem-title a")
                    if not title_elem:
                        continue

                    title = await title_elem.text_content()
                    href = await title_elem.get_attribute("href")

                    # å¤„ç†ç›¸å¯¹é“¾æ¥
                    if href and not href.startswith("http"):
                        href = f"https://www.zhihu.com{href}"

                    # æå–ç‚¹èµæ•°
                    likes = 0
                    vote_elem = await card.query_selector(".VoteButton--up, [class*='VoteButton']")
                    if vote_elem:
                        vote_text = await vote_elem.text_content()
                        likes = self._parse_number(vote_text)

                    # æå–ä½œè€…
                    author = ""
                    author_elem = await card.query_selector(".AuthorInfo-name, .UserLink-link")
                    if author_elem:
                        author = await author_elem.text_content()

                    if title:
                        articles.append({
                            "title": title.strip(),
                            "url": href or "",
                            "likes": likes,
                            "author": author.strip() if author else ""
                        })

                except Exception as e:
                    print(f"   âš ï¸ æå–ç¬¬ {idx + 1} æ¡ç»“æœå¤±è´¥: {e}")
                    continue

            # æ‰“å°ç»“æœ
            print("\n" + "=" * 60)
            print(f"ğŸ“Š çŸ¥ä¹æœç´¢ç»“æœ (å…³é”®è¯: {REAL_TEST_KEYWORD})")
            print("=" * 60)

            if articles:
                for i, article in enumerate(articles[:10], 1):  # åªæ˜¾ç¤ºå‰ 10 æ¡
                    print(f"\n{i}. ğŸ“„ æ ‡é¢˜: {article['title'][:50]}...")
                    print(f"   ğŸ‘ ç‚¹èµæ•°: {article['likes']}")
                    print(f"   âœï¸  ä½œè€…: {article['author']}")
                    print(f"   ğŸ”— é“¾æ¥: {article['url'][:60]}...")
            else:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ")

            print("\n" + "=" * 60)
            print(f"âœ… çŸ¥ä¹æœç´¢æµ‹è¯•å®Œæˆï¼Œå…±æŠ“å– {len(articles)} ç¯‡æ–‡ç« ")
            print("=" * 60)

            # éªŒè¯ç»“æœ
            assert len(articles) > 0, "åº”è¯¥æŠ“å–åˆ°è‡³å°‘ä¸€ç¯‡æ–‡ç« "

        except Exception as e:
            # æˆªå›¾ä¿å­˜
            import os
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            screenshot_path = f"tests/reports/screenshots/zhihu_error_{timestamp}.png"
            os.makedirs(os.path.dirname(screenshot_path), exist_ok=True)
            await page.screenshot(path=screenshot_path)
            print(f"\nâŒ å‘ç”Ÿå¼‚å¸¸ï¼Œæˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            raise e

        finally:
            await page.wait_for_timeout(2000)  # ä¿æŒæµè§ˆå™¨æ‰“å¼€ 2 ç§’ï¼Œä¾¿äºæŸ¥çœ‹ç»“æœ
            await context.close()

    @pytest.mark.asyncio
    async def test_toutiao_real_search(self, real_browser):
        """
        æµ‹è¯•å¤´æ¡çœŸå®æœç´¢

        ä¼šæ‰“å¼€çœŸå®æµè§ˆå™¨ï¼Œæœç´¢å…³é”®è¯ï¼Œå¹¶æ‰“å°ç»“æœ
        """
        browser, playwright = real_browser

        print("\n" + "=" * 60)
        print("ğŸ” å¼€å§‹å¤´æ¡çœŸå®ç¯å¢ƒæœç´¢æµ‹è¯•")
        print("=" * 60)

        # åˆ›å»ºæµè§ˆå™¨ä¸Šä¸‹æ–‡
        context = await browser.new_context(
            viewport={"width": 1280, "height": 800},
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.0.0 Safari/537.36",
        )
        # é˜²æ­¢ WebDriver æ£€æµ‹
        await context.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined
            });
        """)
        
        page = await context.new_page()

        try:
            # å¯¼èˆªåˆ°å¤´æ¡æœç´¢é¡µ
            search_url = f"https://so.toutiao.com/search?dvpf=pc&source=search_subtab_switch&enable_druid_v2=1&keyword={REAL_TEST_KEYWORD}&pd=information&action_type=search_subtab_switch&page_num=0&search_id=&from=news&cur_tab_title=news"
            print(f"ğŸ“Œ è®¿é—® URL: {search_url}")

            await page.goto(search_url, wait_until="networkidle")
            
            # å¢åŠ å»¶æ—¶ï¼Œç­‰å¾…é¡µé¢åŠ è½½
            print("â³ ç­‰å¾…é¡µé¢åŠ è½½ (5s)...")
            await page.wait_for_timeout(5000)

            # æ£€æµ‹ç™»å½•å¼¹çª—
            await self._handle_login_popup(page)

            # æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹
            print("ğŸ“œ æ»šåŠ¨é¡µé¢åŠ è½½æ›´å¤šå†…å®¹...")
            for i in range(3):
                # æ£€æµ‹ç™»å½•å¼¹çª—
                await self._handle_login_popup(page)
                
                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await page.wait_for_timeout(3000)  # æ¯æ¬¡æ»šåŠ¨åç­‰å¾… 3 ç§’
                print(f"   æ»šåŠ¨ {i + 1}/3 å®Œæˆ")

            # æå–æœç´¢ç»“æœ
            print("\nğŸ“ æå–æœç´¢ç»“æœ...")
            articles = []

            # å¤´æ¡çš„æœç´¢ç»“æœé€‰æ‹©å™¨
            cards = await page.query_selector_all("[class*='result-content'], .result-item, .article-card, [class*='cs-view']")
            print(f"   æ‰¾åˆ° {len(cards)} ä¸ªæœç´¢ç»“æœå¡ç‰‡")

            for idx, card in enumerate(cards):
                try:
                    # æå–æ ‡é¢˜å’Œé“¾æ¥
                    title_elem = await card.query_selector("a[class*='title'], .title a, h3 a, [class*='text']")
                    if not title_elem:
                        continue

                    title = await title_elem.text_content()
                    href = await title_elem.get_attribute("href")

                    # å¤„ç†ç›¸å¯¹é“¾æ¥
                    if href and not href.startswith("http"):
                        href = f"https://www.toutiao.com{href}"

                    # æå–é˜…è¯»é‡/è¯„è®ºæ•°
                    reads = 0
                    meta_elem = await card.query_selector("[class*='read'], [class*='comment'], .meta, [class*='count']")
                    if meta_elem:
                        meta_text = await meta_elem.text_content()
                        reads = self._parse_number(meta_text)

                    # æå–ä½œè€…
                    author = ""
                    author_elem = await card.query_selector("[class*='source'], [class*='author'], .name, [class*='user']")
                    if author_elem:
                        author = await author_elem.text_content()

                    if title and len(title.strip()) > 5:
                        articles.append({
                            "title": title.strip(),
                            "url": href or "",
                            "likes": reads // 100 if reads else 0,  # ä¼°ç®—ç‚¹èµæ•°
                            "reads": reads,
                            "author": author.strip() if author else ""
                        })

                except Exception as e:
                    print(f"   âš ï¸ æå–ç¬¬ {idx + 1} æ¡ç»“æœå¤±è´¥: {e}")
                    continue

            # æ‰“å°ç»“æœ
            print("\n" + "=" * 60)
            print(f"ğŸ“Š å¤´æ¡æœç´¢ç»“æœ (å…³é”®è¯: {REAL_TEST_KEYWORD})")
            print("=" * 60)

            if articles:
                for i, article in enumerate(articles[:10], 1):  # åªæ˜¾ç¤ºå‰ 10 æ¡
                    print(f"\n{i}. ğŸ“„ æ ‡é¢˜: {article['title'][:50]}...")
                    print(f"   ğŸ‘ ç‚¹èµæ•°: {article['likes']} (ä¼°ç®—)")
                    print(f"   ğŸ‘ï¸  é˜…è¯»é‡: {article['reads']}")
                    print(f"   âœï¸  ä½œè€…: {article['author']}")
                    print(f"   ğŸ”— é“¾æ¥: {article['url'][:60]}..." if article['url'] else "   ğŸ”— é“¾æ¥: æ— ")
            else:
                print("âŒ æœªæ‰¾åˆ°ä»»ä½•æ–‡ç« ")

            print("\n" + "=" * 60)
            print(f"âœ… å¤´æ¡æœç´¢æµ‹è¯•å®Œæˆï¼Œå…±æŠ“å– {len(articles)} ç¯‡æ–‡ç« ")
            print("=" * 60)

            # éªŒè¯ç»“æœ
            assert len(articles) >= 0, "å¤´æ¡æœç´¢åº”è¯¥æ­£å¸¸å®Œæˆ"

        except Exception as e:
            # æˆªå›¾ä¿å­˜
            import os
            timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
            screenshot_path = f"tests/reports/screenshots/toutiao_error_{timestamp}.png"
            os.makedirs(os.path.dirname(screenshot_path), exist_ok=True)
            await page.screenshot(path=screenshot_path)
            print(f"\nâŒ å‘ç”Ÿå¼‚å¸¸ï¼Œæˆªå›¾å·²ä¿å­˜: {screenshot_path}")
            raise e

        finally:
            await page.wait_for_timeout(2000)  # ä¿æŒæµè§ˆå™¨æ‰“å¼€ 2 ç§’ï¼Œä¾¿äºæŸ¥çœ‹ç»“æœ
            await context.close()

    @pytest.mark.asyncio
    async def test_full_collection_real(self, real_browser):
        """
        æµ‹è¯•å®Œæ•´çš„çœŸå®é‡‡é›†æµç¨‹

        ä½¿ç”¨ ArticleCollectorService è¿›è¡ŒçœŸå®é‡‡é›†
        """
        browser, playwright = real_browser

        print("\n" + "=" * 60)
        print("ğŸš€ å¼€å§‹å®Œæ•´çœŸå®é‡‡é›†æµ‹è¯•")
        print("=" * 60)

        # æ³¨æ„ï¼šè¿™é‡Œä¸ä½¿ç”¨ Mockï¼Œç›´æ¥è°ƒç”¨çœŸå®æœåŠ¡
        from backend.services.article_collector_service import ArticleCollectorService
        from backend.services.playwright_mgr import playwright_mgr
        from backend.services.playwright.collectors import register_collectors
        from backend.config import PLATFORMS

        # æ³¨å†Œæ”¶é›†å™¨
        register_collectors(PLATFORMS)

        # åˆ›å»ºæœåŠ¡å®ä¾‹ï¼ˆä¸ä¼ å…¥ dbï¼Œé¿å…ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
        service = ArticleCollectorService(db=None)

        try:
            # å¯åŠ¨ Playwrightï¼ˆä½¿ç”¨å…¨å±€ç®¡ç†å™¨ï¼‰
            await playwright_mgr.start()

            # æ‰§è¡Œé‡‡é›†ï¼ˆä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼Œä¸åŒæ­¥åˆ° RAGFlowï¼‰
            print(f"\nğŸ“Œ å¼€å§‹é‡‡é›†: å…³é”®è¯={REAL_TEST_KEYWORD}, å¹³å°=['zhihu', 'toutiao']")

            result = await service.collect_trending_articles(
                keyword=REAL_TEST_KEYWORD,
                platforms=["zhihu", "toutiao"],
                min_likes=50,  # é™ä½é˜ˆå€¼ä»¥è·å–æ›´å¤šç»“æœ
                min_reads=500,
                max_articles_per_platform=5,
                save_to_db=False,  # ä¸ä¿å­˜åˆ°æ•°æ®åº“
                sync_to_ragflow=False  # ä¸åŒæ­¥åˆ° RAGFlow
            )

            # æ‰“å°ç»“æœ
            print("\n" + "=" * 60)
            print("ğŸ“Š å®Œæ•´é‡‡é›†ç»“æœæ±‡æ€»")
            print("=" * 60)
            print(f"âœ… é‡‡é›†æˆåŠŸ: {result['success']}")
            print(f"ğŸ“ æ€»æ–‡ç« æ•°: {result['total_count']}")

            for platform, articles in result['results'].items():
                print(f"\n--- {platform.upper()} å¹³å° ({len(articles)} ç¯‡) ---")
                for i, article in enumerate(articles[:5], 1):
                    print(f"\n{i}. ğŸ“„ æ ‡é¢˜: {article.get('title', 'æ— æ ‡é¢˜')[:50]}...")
                    print(f"   ğŸ‘ ç‚¹èµæ•°: {article.get('likes', 0)}")
                    print(f"   ğŸ‘ï¸  é˜…è¯»é‡: {article.get('reads', 0)}")
                    print(f"   âœï¸  ä½œè€…: {article.get('author', 'æœªçŸ¥')}")

            print("\n" + "=" * 60)
            print("âœ… å®Œæ•´é‡‡é›†æµ‹è¯•å®Œæˆ")
            print("=" * 60)

            # éªŒè¯
            assert result["success"] is True, "é‡‡é›†åº”è¯¥æˆåŠŸ"

        except Exception as e:
            print(f"\nâŒ é‡‡é›†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

        finally:
            # ä¸å…³é—­ playwright_mgrï¼Œå› ä¸ºå®ƒå¯èƒ½è¢«å…¶ä»–æµ‹è¯•ä½¿ç”¨
            pass

    def _parse_number(self, text: str) -> int:
        """è§£ææ•°å­—ï¼ˆæ”¯æŒ 1.2k, 1.5w ç­‰æ ¼å¼ï¼‰"""
        import re

        if not text:
            return 0

        text = text.strip().lower()

        # ç§»é™¤éæ•°å­—å­—ç¬¦ä½†ä¿ç•™ kã€wã€ä¸‡
        match = re.search(r'([\d.]+)\s*([kwmä¸‡])?', text)
        if not match:
            return 0

        num = float(match.group(1))
        unit = match.group(2)

        if unit in ['k', 'K']:
            num *= 1000
        elif unit in ['w', 'W', 'ä¸‡']:
            num *= 10000
        elif unit in ['m', 'M']:
            num *= 1000000

        return int(num)


# ==================== Service å•å…ƒæµ‹è¯• ====================

class TestArticleCollectorService:
    """ArticleCollectorService å•å…ƒæµ‹è¯•"""

    def test_clean_html_removes_script_tags(self):
        """æµ‹è¯• HTML æ¸…æ´—ï¼šç§»é™¤ script æ ‡ç­¾"""
        service = ArticleCollectorService()

        html_content = '<p>æ­£æ–‡å†…å®¹</p><script>alert("xss")</script><p>æ›´å¤šå†…å®¹</p>'
        cleaned = service._clean_html(html_content)

        assert "script" not in cleaned.lower()
        assert "alert" not in cleaned
        assert "æ­£æ–‡å†…å®¹" in cleaned
        assert "æ›´å¤šå†…å®¹" in cleaned

    def test_clean_html_removes_style_tags(self):
        """æµ‹è¯• HTML æ¸…æ´—ï¼šç§»é™¤ style æ ‡ç­¾"""
        service = ArticleCollectorService()

        html_content = '<p>æ­£æ–‡å†…å®¹</p><style>.hidden{display:none}</style>'
        cleaned = service._clean_html(html_content)

        assert "style" not in cleaned.lower()
        assert "display" not in cleaned
        assert "æ­£æ–‡å†…å®¹" in cleaned

    def test_clean_html_removes_ad_content(self):
        """æµ‹è¯• HTML æ¸…æ´—ï¼šç§»é™¤å¹¿å‘Šå†…å®¹"""
        service = ArticleCollectorService()

        html_content = '''
        <p>æ­£æ–‡å†…å®¹</p>
        <div class="advertisement">å¹¿å‘Šå†…å®¹</div>
        <p>æ›´å¤šæ­£æ–‡</p>
        '''
        cleaned = service._clean_html(html_content)

        assert "æ­£æ–‡å†…å®¹" in cleaned
        assert "æ›´å¤šæ­£æ–‡" in cleaned

    def test_clean_html_converts_entities(self):
        """æµ‹è¯• HTML æ¸…æ´—ï¼šè½¬æ¢ HTML å®ä½“"""
        service = ArticleCollectorService()

        html_content = '&nbsp;&lt;æµ‹è¯•&gt;&amp;å†…å®¹&nbsp;'
        cleaned = service._clean_html(html_content)

        assert "<æµ‹è¯•>" in cleaned
        assert "&å†…å®¹" in cleaned

    def test_clean_html_removes_extra_whitespace(self):
        """æµ‹è¯• HTML æ¸…æ´—ï¼šç§»é™¤å¤šä½™ç©ºç™½"""
        service = ArticleCollectorService()

        html_content = 'æ­£æ–‡    å†…å®¹\n\n\n\næ›´å¤šå†…å®¹'
        cleaned = service._clean_html(html_content)

        # è¿ç»­ç©ºæ ¼åº”è¯¥è¢«åˆå¹¶
        assert "    " not in cleaned
        # è¿ç»­æ¢è¡Œåº”è¯¥è¢«åˆå¹¶
        assert "\n\n\n" not in cleaned

    def test_clean_html_empty_content(self):
        """æµ‹è¯• HTML æ¸…æ´—ï¼šç©ºå†…å®¹"""
        service = ArticleCollectorService()

        assert service._clean_html("") == ""
        assert service._clean_html(None) == ""

    @pytest.mark.asyncio
    async def test_sync_to_ragflow_not_configured(self):
        """æµ‹è¯• RAGFlow åŒæ­¥ï¼šæœªé…ç½®æ—¶è·³è¿‡"""
        service = ArticleCollectorService()

        # Mock RAGFlow å®¢æˆ·ç«¯æœªé…ç½®
        with patch.object(service._ragflow, 'is_configured', return_value=False):
            result = await service._sync_to_ragflow({
                "title": "æµ‹è¯•æ–‡ç« ",
                "content": "æµ‹è¯•å†…å®¹"
            })

        assert result["success"] is False
        assert "æœªé…ç½®" in result["error_msg"]

    @pytest.mark.asyncio
    async def test_collect_trending_articles_mock(self):
        """æµ‹è¯•é‡‡é›†çˆ†ç«æ–‡ç« ï¼ˆMock Playwrightï¼‰"""
        service = ArticleCollectorService()

        # Mock æ•°æ®
        mock_zhihu_articles = [
            CollectedArticle(
                title="çŸ¥ä¹çƒ­é—¨æ–‡ç« 1",
                url="https://zhihu.com/p/123",
                content="è¿™æ˜¯çŸ¥ä¹æ–‡ç« å†…å®¹",
                likes=500,
                reads=10000,
                comments=100,
                author="çŸ¥ä¹ä½œè€…",
                platform="zhihu"
            )
        ]
        mock_toutiao_articles = [
            CollectedArticle(
                title="å¤´æ¡çƒ­é—¨æ–‡ç« 1",
                url="https://toutiao.com/a/456",
                content="è¿™æ˜¯å¤´æ¡æ–‡ç« å†…å®¹",
                likes=300,
                reads=20000,
                comments=50,
                author="å¤´æ¡ä½œè€…",
                platform="toutiao"
            )
        ]

        # Mock Playwright ç®¡ç†å™¨å’Œæ”¶é›†å™¨
        with patch('backend.services.article_collector_service.playwright_mgr') as mock_mgr, \
             patch('backend.services.article_collector_service.get_collector') as mock_get_collector, \
             patch('backend.services.article_collector_service.register_collectors'):

            # è®¾ç½® Mock è¡Œä¸º
            mock_mgr.start = AsyncMock()
            mock_mgr._browser = MagicMock()

            # Mock æµè§ˆå™¨ä¸Šä¸‹æ–‡
            mock_context = AsyncMock()
            mock_page = AsyncMock()
            mock_context.new_page = AsyncMock(return_value=mock_page)
            mock_page.close = AsyncMock()
            mock_context.close = AsyncMock()
            mock_mgr._browser.new_context = AsyncMock(return_value=mock_context)

            # Mock çŸ¥ä¹æ”¶é›†å™¨
            mock_zhihu_collector = MagicMock()
            mock_zhihu_collector.name = "çŸ¥ä¹"
            mock_zhihu_collector.collect = AsyncMock(return_value=mock_zhihu_articles)

            # Mock å¤´æ¡æ”¶é›†å™¨
            mock_toutiao_collector = MagicMock()
            mock_toutiao_collector.name = "ä»Šæ—¥å¤´æ¡"
            mock_toutiao_collector.collect = AsyncMock(return_value=mock_toutiao_articles)

            def get_collector_side_effect(platform):
                if platform == "zhihu":
                    return mock_zhihu_collector
                elif platform == "toutiao":
                    return mock_toutiao_collector
                return None

            mock_get_collector.side_effect = get_collector_side_effect

            # æ‰§è¡Œé‡‡é›†ï¼ˆä¸ä¿å­˜åˆ°æ•°æ®åº“ï¼‰
            result = await service.collect_trending_articles(
                keyword="äººå·¥æ™ºèƒ½",
                platforms=["zhihu", "toutiao"],
                min_likes=100,
                min_reads=1000,
                max_articles_per_platform=5,
                save_to_db=False,
                sync_to_ragflow=False
            )

        # éªŒè¯ç»“æœ
        assert result["success"] is True
        assert result["keyword"] == "äººå·¥æ™ºèƒ½"
        assert result["total_count"] == 2
        assert "zhihu" in result["results"]
        assert "toutiao" in result["results"]

    def test_get_supported_platforms(self):
        """æµ‹è¯•è·å–æ”¯æŒçš„å¹³å°åˆ—è¡¨"""
        service = ArticleCollectorService()

        # åˆå§‹åŒ–ååº”è¯¥æœ‰æ”¯æŒçš„å¹³å°
        with patch('backend.services.article_collector_service.register_collectors'):
            with patch('backend.services.article_collector_service.list_collectors') as mock_list:
                mock_list.return_value = {"zhihu": MagicMock(), "toutiao": MagicMock()}
                platforms = service.get_supported_platforms()

        assert "zhihu" in platforms
        assert "toutiao" in platforms


# ==================== API é›†æˆæµ‹è¯• ====================

@pytest.mark.integration
class TestArticleCollectionAPI:
    """æ–‡ç« æ”¶é›† API é›†æˆæµ‹è¯•"""

    def test_start_collect_api_exists(self, backend_server):
        """æµ‹è¯•é‡‡é›†å¯åŠ¨ API å­˜åœ¨"""
        data = MockArticleData.collect_request()
        response = requests.post(f"{COLLECT_API}/start", json=data)

        # API åº”è¯¥å­˜åœ¨å¹¶è¿”å›æœ‰æ•ˆå“åº”
        assert response.status_code in [200, 201, 400, 422]

    def test_start_collect_invalid_platform(self, backend_server):
        """æµ‹è¯•é‡‡é›†å¯åŠ¨ APIï¼šæ— æ•ˆå¹³å°"""
        data = {
            "keyword": "æµ‹è¯•",
            "platforms": ["invalid_platform"],
            "min_likes": 100
        }
        response = requests.post(f"{COLLECT_API}/start", json=data)

        # åº”è¯¥è¿”å›é”™è¯¯
        assert response.status_code == 400

    def test_start_collect_missing_keyword(self, backend_server):
        """æµ‹è¯•é‡‡é›†å¯åŠ¨ APIï¼šç¼ºå°‘å…³é”®è¯"""
        data = {
            "platforms": ["zhihu"]
        }
        response = requests.post(f"{COLLECT_API}/start", json=data)

        # åº”è¯¥è¿”å›éªŒè¯é”™è¯¯
        assert response.status_code == 422

    def test_start_collect_empty_platforms(self, backend_server):
        """æµ‹è¯•é‡‡é›†å¯åŠ¨ APIï¼šç©ºå¹³å°åˆ—è¡¨"""
        data = {
            "keyword": "æµ‹è¯•",
            "platforms": []
        }
        response = requests.post(f"{COLLECT_API}/start", json=data)

        # åº”è¯¥è¿”å›éªŒè¯é”™è¯¯
        assert response.status_code == 422

    def test_get_collect_status_not_found(self, backend_server):
        """æµ‹è¯•è·å–é‡‡é›†çŠ¶æ€ï¼šä»»åŠ¡ä¸å­˜åœ¨"""
        response = requests.get(f"{COLLECT_API}/status/non-existent-task-id")

        assert response.status_code == 404

    def test_list_collect_tasks(self, backend_server):
        """æµ‹è¯•è·å–é‡‡é›†ä»»åŠ¡åˆ—è¡¨"""
        response = requests.get(f"{COLLECT_API}/tasks")

        assert response.status_code == 200
        result = response.json()
        assert isinstance(result, list)

    def test_list_collect_tasks_with_status_filter(self, backend_server):
        """æµ‹è¯•è·å–é‡‡é›†ä»»åŠ¡åˆ—è¡¨ï¼šæŒ‰çŠ¶æ€ç­›é€‰"""
        response = requests.get(f"{COLLECT_API}/tasks?status=completed")

        assert response.status_code == 200
        result = response.json()
        assert isinstance(result, list)

    def test_get_supported_platforms_api(self, backend_server):
        """æµ‹è¯•è·å–æ”¯æŒå¹³å° API"""
        response = requests.get(f"{COLLECT_API}/platforms")

        assert response.status_code == 200
        result = response.json()
        assert "platforms" in result
        assert len(result["platforms"]) >= 2

        # éªŒè¯å¹³å°æ•°æ®ç»“æ„
        for platform in result["platforms"]:
            assert "id" in platform
            assert "name" in platform

        # éªŒè¯å¹³å°æ•°æ®ç»“æ„
        for platform in result["platforms"]:
            assert "id" in platform
            assert "name" in platform

    def test_check_duplicate_api(self, backend_server):
        """æµ‹è¯•å»é‡æ£€æŸ¥ API"""
        data = {
            "content": "è¿™æ˜¯ä¸€æ®µå¾…æ£€æŸ¥çš„å†…å®¹ï¼Œç”¨äºæµ‹è¯•å»é‡åŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚" * 10,
            "threshold": 0.85
        }
        response = requests.post(f"{COLLECT_API}/check-duplicate", json=data)

        assert response.status_code == 200
        result = response.json()
        assert "checked" in result
        assert "is_duplicate" in result
        assert "threshold" in result

    def test_check_duplicate_short_content(self, backend_server):
        """æµ‹è¯•å»é‡æ£€æŸ¥ APIï¼šå†…å®¹è¿‡çŸ­"""
        data = {
            "content": "çŸ­å†…å®¹",
            "threshold": 0.85
        }
        response = requests.post(f"{COLLECT_API}/check-duplicate", json=data)

        # åº”è¯¥è¿”å›éªŒè¯é”™è¯¯ï¼ˆå†…å®¹æœ€å°‘10å­—ç¬¦ï¼‰
        assert response.status_code == 422


# ==================== æ•°æ®åº“æ¨¡å‹æµ‹è¯• ====================

class TestReferenceArticleModel:
    """ReferenceArticle æ¨¡å‹æµ‹è¯•"""

    def test_create_reference_article(self, clean_db):
        """æµ‹è¯•åˆ›å»ºå‚è€ƒæ–‡ç« """
        article = ReferenceArticle(
            title="æµ‹è¯•çˆ†ç«æ–‡ç« ",
            url="https://zhihu.com/p/test123",
            content="è¿™æ˜¯æ–‡ç« æ­£æ–‡å†…å®¹",
            summary="è¿™æ˜¯æ‘˜è¦",
            platform="zhihu",
            author="æµ‹è¯•ä½œè€…",
            likes=500,
            reads=10000,
            comments=100,
            keyword="äººå·¥æ™ºèƒ½",
            ragflow_synced=False,
            status=1
        )
        clean_db.add(article)
        clean_db.commit()
        clean_db.refresh(article)

        assert article.id is not None
        assert article.title == "æµ‹è¯•çˆ†ç«æ–‡ç« "
        assert article.platform == "zhihu"
        assert article.likes == 500

    def test_reference_article_unique_url(self, clean_db):
        """æµ‹è¯•å‚è€ƒæ–‡ç«  URL å”¯ä¸€æ€§"""
        article1 = ReferenceArticle(
            title="æ–‡ç« 1",
            url="https://zhihu.com/p/unique123",
            content="å†…å®¹1",
            platform="zhihu",
            status=1
        )
        clean_db.add(article1)
        clean_db.commit()

        # å°è¯•æ·»åŠ ç›¸åŒ URL çš„æ–‡ç« åº”è¯¥å¤±è´¥
        article2 = ReferenceArticle(
            title="æ–‡ç« 2",
            url="https://zhihu.com/p/unique123",  # ç›¸åŒ URL
            content="å†…å®¹2",
            platform="zhihu",
            status=1
        )
        clean_db.add(article2)

        with pytest.raises(Exception):
            clean_db.commit()

        clean_db.rollback()

    def test_reference_article_fields(self, clean_db):
        """æµ‹è¯•å‚è€ƒæ–‡ç« æ‰€æœ‰å­—æ®µ"""
        article = ReferenceArticle(
            title="å®Œæ•´æµ‹è¯•æ–‡ç« ",
            url="https://toutiao.com/a/test456",
            content="è¯¦ç»†æ­£æ–‡å†…å®¹" * 100,
            summary="æ‘˜è¦å†…å®¹",
            platform="toutiao",
            author="å¤´æ¡ä½œè€…",
            publish_time="2025-01-26",
            likes=1000,
            reads=50000,
            comments=200,
            keyword="ç§‘æŠ€æ–°é—»",
            ragflow_synced=True,
            ragflow_doc_id="doc_123",
            status=1
        )
        clean_db.add(article)
        clean_db.commit()
        clean_db.refresh(article)

        # éªŒè¯æ‰€æœ‰å­—æ®µ
        assert article.id is not None
        assert article.title == "å®Œæ•´æµ‹è¯•æ–‡ç« "
        assert article.url == "https://toutiao.com/a/test456"
        assert len(article.content) > 100
        assert article.summary == "æ‘˜è¦å†…å®¹"
        assert article.platform == "toutiao"
        assert article.author == "å¤´æ¡ä½œè€…"
        assert article.likes == 1000
        assert article.reads == 50000
        assert article.comments == 200
        assert article.keyword == "ç§‘æŠ€æ–°é—»"
        assert article.ragflow_synced is True
        assert article.ragflow_doc_id == "doc_123"
        assert article.created_at is not None

    def test_reference_article_soft_delete(self, clean_db):
        """æµ‹è¯•å‚è€ƒæ–‡ç« è½¯åˆ é™¤"""
        article = ReferenceArticle(
            title="å¾…åˆ é™¤æ–‡ç« ",
            url="https://zhihu.com/p/delete123",
            content="å†…å®¹",
            platform="zhihu",
            status=1
        )
        clean_db.add(article)
        clean_db.commit()

        # è½¯åˆ é™¤
        article.status = 0
        clean_db.commit()

        # éªŒè¯çŠ¶æ€
        deleted_article = clean_db.query(ReferenceArticle).filter(
            ReferenceArticle.url == "https://zhihu.com/p/delete123"
        ).first()
        assert deleted_article.status == 0


# ==================== æ”¶é›†å™¨å•å…ƒæµ‹è¯• ====================

class TestCollectors:
    """æ”¶é›†å™¨å•å…ƒæµ‹è¯•"""

    def test_zhihu_collector_parse_number(self):
        """æµ‹è¯•çŸ¥ä¹æ”¶é›†å™¨æ•°å­—è§£æ"""
        from backend.services.playwright.collectors.zhihu import ZhihuCollector

        collector = ZhihuCollector("zhihu", {"name": "çŸ¥ä¹"})

        # æµ‹è¯•å„ç§æ•°å­—æ ¼å¼
        assert collector._parse_number("123") == 123
        assert collector._parse_number("1.5k") == 1500
        assert collector._parse_number("2.3K") == 2300
        assert collector._parse_number("1w") == 10000
        assert collector._parse_number("1.5ä¸‡") == 15000
        assert collector._parse_number("") == 0
        assert collector._parse_number(None) == 0

    def test_toutiao_collector_parse_number(self):
        """æµ‹è¯•å¤´æ¡æ”¶é›†å™¨æ•°å­—è§£æ"""
        from backend.services.playwright.collectors.toutiao import ToutiaoCollector

        collector = ToutiaoCollector("toutiao", {"name": "ä»Šæ—¥å¤´æ¡"})

        # æµ‹è¯•å„ç§æ•°å­—æ ¼å¼
        assert collector._parse_number("456") == 456
        assert collector._parse_number("2k") == 2000
        assert collector._parse_number("3.5ä¸‡") == 35000
        assert collector._parse_number("") == 0

    def test_base_collector_filter_trending(self):
        """æµ‹è¯•åŸºç¡€æ”¶é›†å™¨ç­›é€‰çˆ†ç«æ–‡ç« """
        from backend.services.playwright.collectors.base import BaseCollector

        # åˆ›å»ºæµ‹è¯•å­ç±»
        class TestCollector(BaseCollector):
            async def search(self, page, keyword):
                return []

            async def extract_content(self, page, url):
                return ""

        collector = TestCollector("test", {"name": "æµ‹è¯•"})
        collector.min_likes = 100
        collector.min_reads = 1000

        articles = [
            {"title": "é«˜èµæ–‡ç« ", "likes": 500, "reads": 500},
            {"title": "é«˜é˜…è¯»æ–‡ç« ", "likes": 50, "reads": 5000},
            {"title": "æ™®é€šæ–‡ç« ", "likes": 10, "reads": 100},
            {"title": "è¾¹ç•Œæ–‡ç« ", "likes": 100, "reads": 999},
        ]

        trending = collector._filter_trending(articles)

        # éªŒè¯ç­›é€‰ç»“æœ
        assert len(trending) == 2
        titles = [a["title"] for a in trending]
        assert "é«˜èµæ–‡ç« " in titles
        assert "é«˜é˜…è¯»æ–‡ç« " in titles
        assert "æ™®é€šæ–‡ç« " not in titles


# ==================== å‚è€ƒæ–‡ç«  API æµ‹è¯• ====================

@pytest.mark.integration
class TestReferenceArticlesAPI:
    """å‚è€ƒæ–‡ç«  API æµ‹è¯•"""

    def test_list_reference_articles(self, backend_server):
        """æµ‹è¯•è·å–å‚è€ƒæ–‡ç« åˆ—è¡¨"""
        response = requests.get(f"{COLLECT_API}/articles")

        assert response.status_code == 200
        result = response.json()
        assert "total" in result
        assert "items" in result
        assert isinstance(result["items"], list)

    def test_list_reference_articles_with_platform_filter(self, backend_server):
        """æµ‹è¯•è·å–å‚è€ƒæ–‡ç« åˆ—è¡¨ï¼šæŒ‰å¹³å°ç­›é€‰"""
        response = requests.get(f"{COLLECT_API}/articles?platform=zhihu")

        assert response.status_code == 200
        result = response.json()
        assert "items" in result

    def test_list_reference_articles_with_keyword_filter(self, backend_server):
        """æµ‹è¯•è·å–å‚è€ƒæ–‡ç« åˆ—è¡¨ï¼šæŒ‰å…³é”®è¯ç­›é€‰"""
        response = requests.get(f"{COLLECT_API}/articles?keyword=äººå·¥æ™ºèƒ½")

        assert response.status_code == 200
        result = response.json()
        assert "items" in result

    def test_list_reference_articles_pagination(self, backend_server):
        """æµ‹è¯•è·å–å‚è€ƒæ–‡ç« åˆ—è¡¨ï¼šåˆ†é¡µ"""
        response = requests.get(f"{COLLECT_API}/articles?page=1&page_size=5")

        assert response.status_code == 200
        result = response.json()
        assert "total" in result
        assert "items" in result
        assert len(result["items"]) <= 5

    def test_get_reference_article_not_found(self, backend_server):
        """æµ‹è¯•è·å–å‚è€ƒæ–‡ç« è¯¦æƒ…ï¼šä¸å­˜åœ¨"""
        response = requests.get(f"{COLLECT_API}/articles/99999")

        assert response.status_code == 404

    def test_delete_reference_article_not_found(self, backend_server):
        """æµ‹è¯•åˆ é™¤å‚è€ƒæ–‡ç« ï¼šä¸å­˜åœ¨"""
        response = requests.delete(f"{COLLECT_API}/articles/99999")

        assert response.status_code == 404


# ==================== å®Œæ•´æµç¨‹æµ‹è¯•ï¼ˆMock ç‰ˆæœ¬ï¼‰====================

class TestCollectFlowMocked:
    """å®Œæ•´é‡‡é›†æµç¨‹æµ‹è¯•ï¼ˆMock æµè§ˆå™¨ï¼‰"""

    @pytest.mark.asyncio
    async def test_full_collect_flow_mocked(self, clean_db):
        """æµ‹è¯•å®Œæ•´é‡‡é›†æµç¨‹ï¼ˆMockï¼‰"""
        # åˆ›å»ºæœåŠ¡å®ä¾‹
        service = ArticleCollectorService(db=clean_db)

        # Mock æ–‡ç« æ•°æ®
        mock_articles = [
            CollectedArticle(
                title="Mock çˆ†ç«æ–‡ç« ",
                url=f"https://zhihu.com/p/mock_{i}",
                content="è¿™æ˜¯ Mock æ–‡ç« å†…å®¹" * 50,
                likes=500 + i * 100,
                reads=10000 + i * 1000,
                comments=100,
                author="Mock ä½œè€…",
                platform="zhihu"
            )
            for i in range(3)
        ]

        # Mock Playwright å’Œæ”¶é›†å™¨
        with patch('backend.services.article_collector_service.playwright_mgr') as mock_mgr, \
             patch('backend.services.article_collector_service.get_collector') as mock_get_collector, \
             patch('backend.services.article_collector_service.register_collectors'), \
             patch.object(service._ragflow, 'is_configured', return_value=False):

            # è®¾ç½® Mock
            mock_mgr.start = AsyncMock()
            mock_mgr._browser = MagicMock()

            # Mock æµè§ˆå™¨ä¸Šä¸‹æ–‡
            mock_context = AsyncMock()
            mock_page = AsyncMock()
            mock_context.new_page = AsyncMock(return_value=mock_page)
            mock_page.close = AsyncMock()
            mock_context.close = AsyncMock()
            mock_mgr._browser.new_context = AsyncMock(return_value=mock_context)

            mock_collector = MagicMock()
            mock_collector.name = "çŸ¥ä¹"
            mock_collector.collect = AsyncMock(return_value=mock_articles)
            mock_get_collector.return_value = mock_collector

            # æ‰§è¡Œé‡‡é›†
            result = await service.collect_trending_articles(
                keyword="äººå·¥æ™ºèƒ½",
                platforms=["zhihu"],
                min_likes=100,
                save_to_db=True,
                sync_to_ragflow=False
            )

        # éªŒè¯ç»“æœ
        assert result["success"] is True
        assert result["total_count"] == 3
        assert result["saved_count"] == 3

        # éªŒè¯æ•°æ®åº“
        saved_articles = clean_db.query(ReferenceArticle).filter(
            ReferenceArticle.keyword == "äººå·¥æ™ºèƒ½"
        ).all()
        assert len(saved_articles) == 3

        # æ¸…ç†æµ‹è¯•æ•°æ®
        for article in saved_articles:
            clean_db.delete(article)
        clean_db.commit()
