# -*- coding: utf-8 -*-
"""
çŸ¥ä¹å‘å¸ƒé€‚é…å™¨ - å·¥ä¸šåŠ å›ºç‰ˆ (v3.6)
ä¿®å¤ï¼š
1. ç™»å½•å¤±æ•ˆè‡ªåŠ¨è¯†åˆ« (é˜²æ­¢åœ¨ç™»å½•é¡µæ­»ç­‰è¶…æ—¶)
2. å›¾åƒæœç´¢å…³é”®è¯æ¸…æ´— (é˜²æ­¢æœç´¢ [AIæ­£åœ¨åˆ›ä½œä¸­])
3. å¢å¼ºå›¾æºç¨³å®šæ€§
"""

import asyncio
import re
import os
import httpx
import tempfile
import random
from typing import Dict, Any, List, Optional
from playwright.async_api import Page
from loguru import logger

from .base import BasePublisher, registry


class ZhihuPublisher(BasePublisher):
    async def publish(self, page: Page, article: Any, account: Any) -> Dict[str, Any]:
        temp_files = []
        try:
            logger.info("ğŸš€ å¼€å§‹çŸ¥ä¹å‘å¸ƒ (v3.6 çŠ¶æ€è‡ªæ£€ç‰ˆ)...")

            # 1. å¯¼èˆªå¹¶éªŒè¯ç™»å½•çŠ¶æ€
            await page.goto(self.config["publish_url"], wait_until="networkidle", timeout=60000)
            await asyncio.sleep(5)

            # ğŸŒŸ [å…³é”®ä¿®å¤] æ£€æŸ¥æ˜¯å¦è¢«é‡å®šå‘åˆ°äº†ç™»å½•é¡µ
            if "signin" in page.url or "login" in page.url:
                logger.error("âŒ ç™»å½•å·²å¤±æ•ˆï¼šé¡µé¢è¢«é‡å®šå‘è‡³ç™»å½•é¡µï¼Œè¯·é‡æ–°æ‰«ç æˆæƒè´¦å·")
                return {"success": False, "error_msg": "è´¦å·ç™»å½•å·²è¿‡æœŸï¼Œè¯·é‡æ–°æˆæƒ"}

            # 2. å›¾åƒè·å–é€»è¾‘
            # æ¸…æ´—æ­£æ–‡
            clean_content = re.sub(r'!\[.*?\]\(.*?\)', '', article.content)
            # å°è¯•ä¸‹è½½æ­£æ–‡åŸå›¾
            image_urls = re.findall(r'!\[.*?\]\(((?:https?://)?\S+?)\)', article.content)
            downloaded_paths = await self._download_images(image_urls)

            # ğŸŒŸ [å…³é”®ä¿®å¤] è‡ªåŠ¨é…å›¾ç­–ç•¥ï¼šç¡®ä¿ä¸ä½¿ç”¨å ä½ç¬¦å…³é”®è¯
            if not downloaded_paths:
                # å¦‚æœæ ‡é¢˜åŒ…å«æ­£åœ¨åˆ›ä½œä¸­ï¼Œåˆ™å°è¯•ä½¿ç”¨å…³é”®è¯è¡¨é‡Œçš„åŸè¯
                search_kw = article.title
                if "åˆ›ä½œä¸­" in search_kw or not search_kw:
                    # å…œåº•ï¼šå°è¯•ä»å…³è”çš„å…³é”®è¯å¯¹è±¡è·å–
                    search_kw = "ç§‘æŠ€åˆ›æ–°"  # ç»ˆæå›é€€è¯

                logger.info(f"âš ï¸ æ­£æ–‡æ— æœ‰æ•ˆå›¾ç‰‡ï¼Œå¯åŠ¨è‡ªåŠ¨é…å›¾ã€‚æœç´¢è¯: {search_kw}")
                fallback_path = await self._generate_fallback_image(search_kw)
                if fallback_path:
                    downloaded_paths = [fallback_path]
                    temp_files.append(fallback_path)

            # 3. å¡«å……æ ‡é¢˜ (å¢åŠ å¯¹å ä½æ ‡é¢˜çš„é˜²å¾¡)
            display_title = article.title
            if "åˆ›ä½œä¸­" in display_title:
                await asyncio.sleep(5)  # å†ç­‰5ç§’çœ‹æ•°æ®åº“æ˜¯å¦æ›´æ–°
                # æç¤ºï¼šå®é™…ç”Ÿäº§ä¸­åº”åœ¨ Service å±‚æ‹¦æˆªï¼Œè¿™é‡ŒåšäºŒæ¬¡é˜²å¾¡

            await self._fill_title(page, display_title)

            # 4. å¡«å……å†…å®¹
            await self._fill_content_and_clean_ui(page, clean_content)

            # 5. ä¸Šä¼ å›¾åƒ
            if downloaded_paths:
                await self._upload_real_images(page, downloaded_paths)

            # 6. å‘å¸ƒæµç¨‹
            topic_word = search_kw[:4] if 'search_kw' in locals() else "ç§‘æŠ€"
            if not await self._handle_publish_process(page, topic_word):
                return {"success": False, "error_msg": "å‘å¸ƒç¡®è®¤ç¯èŠ‚å¤±è´¥"}

            return await self._wait_for_publish_result(page)

        except Exception as e:
            logger.exception(f"âŒ çŸ¥ä¹è„šæœ¬ä¸¥é‡æ•…éšœ: {str(e)}")
            return {"success": False, "error_msg": str(e)}
        finally:
            for f in temp_files:
                if os.path.exists(f): os.remove(f)

    async def _download_images(self, urls: List[str]) -> List[str]:
        paths = []
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"}
        async with httpx.AsyncClient(headers=headers, verify=False) as client:
            for i, url in enumerate(urls[:2]):
                try:
                    clean_url = url.strip().strip('"').strip("'")
                    if clean_url.startswith('//'): clean_url = 'https:' + clean_url
                    # è¿‡æ»¤æ‰éæ³•çš„å ä½ç¬¦é“¾æ¥
                    if "loremflickr" in clean_url or "unsplash" in clean_url or "http" in clean_url:
                        resp = await client.get(clean_url, timeout=15.0, follow_redirects=True)
                        if resp.status_code == 200:
                            tmp_path = os.path.join(tempfile.gettempdir(), f"zh_v36_{random.randint(100, 999)}.jpg")
                            with open(tmp_path, "wb") as f:
                                f.write(resp.content)
                            paths.append(tmp_path)
                except:
                    pass
        return paths

    async def _generate_fallback_image(self, keyword: str) -> Optional[str]:
        """å¤‡ç”¨å›¾æºé‡æ„ï¼šä½¿ç”¨æ›´ç¨³å®šçš„æº"""
        clean_kw = re.sub(r'[\[\]\(\)\s]', '', keyword)[:10]
        # ä½¿ç”¨ Unsplash éšæœºå›¾æºåŠ é€Ÿå™¨
        url = f"https://source.unsplash.com/800x600/?business,technology,{clean_kw}"
        return (await self._download_images([url]))[0] if True else None

    async def _fill_content_and_clean_ui(self, page: Page, content: str):
        editor = ".public-DraftEditor-content"
        await page.wait_for_selector(editor)
        await page.click(editor)
        await page.evaluate('''(text) => {
            const dt = new DataTransfer();
            dt.setData("text/plain", text);
            const ev = new ClipboardEvent("paste", { clipboardData: dt, bubbles: true });
            document.querySelector(".public-DraftEditor-content").dispatchEvent(ev);
        }''', content)
        await asyncio.sleep(2)
        try:
            confirm = page.locator("button:has-text('ç¡®è®¤å¹¶è§£æ')").first
            if await confirm.is_visible(timeout=3000):
                await confirm.click()
        except:
            pass

    async def _upload_real_images(self, page: Page, paths: List[str]):
        try:
            logger.info("æ­£åœ¨å°è¯•ä¸Šä¼ å°é¢å›¾...")
            cover_input = page.locator("input.UploadPicture-input").first
            await cover_input.set_input_files(paths[0])
            await asyncio.sleep(4)

            logger.info("æ­£åœ¨æ­£æ–‡æ’å…¥å›¾ç‰‡...")
            await page.keyboard.press("Control+Home")
            await page.keyboard.press("Enter")
            await page.keyboard.press("ArrowUp")
            img_icon = page.locator(".WriteIndex-imageIcon, button[aria-label='æ’å…¥å›¾ç‰‡']").first
            async with page.expect_file_chooser() as fc_info:
                await img_icon.click()
            file_chooser = await fc_info.value
            await file_chooser.set_files(paths[0])
            await asyncio.sleep(5)
        except Exception as e:
            logger.error(f"çœŸå®å›¾ç‰‡ä¸Šä¼ åŠ¨ä½œå¤±è´¥: {e}")

    async def _fill_title(self, page: Page, title: str):
        # é’ˆå¯¹çŸ¥ä¹çš„å¤šç§æ ‡é¢˜è¾“å…¥æ¡†è¿›è¡Œé€‚é…
        sel = "input[placeholder*='æ ‡é¢˜'], .WriteIndex-titleInput textarea, .Input"
        await page.wait_for_selector(sel, timeout=10000)
        await page.fill(sel, title)

    async def _handle_publish_process(self, page: Page, topic: str) -> bool:
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        add_topic = page.locator("button:has-text('æ·»åŠ è¯é¢˜')").first
        if await add_topic.is_visible(timeout=2000):
            await add_topic.click()
        topic_input = page.locator("input[placeholder*='è¯é¢˜']").first
        if await topic_input.is_visible():
            await topic_input.fill(topic)
            await asyncio.sleep(2)
            suggestion = page.locator(".Suggestion-item, .PublishPanel-suggestionItem").first
            if await suggestion.is_visible():
                await suggestion.click()
            else:
                await page.keyboard.press("Enter")
        final_btn = page.locator(
            "button.PublishPanel-submitButton, .WriteIndex-publishButton, button:has-text('å‘å¸ƒ')").last
        for _ in range(5):
            if await final_btn.is_enabled():
                await final_btn.click(force=True)
                return True
            await asyncio.sleep(2)
        return False

    async def _wait_for_publish_result(self, page: Page) -> Dict[str, Any]:
        for i in range(25):
            if "/p/" in page.url and "/edit" not in page.url:
                return {"success": True, "platform_url": page.url}
            await asyncio.sleep(1)
        return {"success": False, "error_msg": "å‘å¸ƒè¶…æ—¶"}


# æ³¨å†Œé€‚é…å™¨
ZHIHU_CONFIG = {"name": "çŸ¥ä¹", "publish_url": "https://zhuanlan.zhihu.com/write", "color": "#0084FF"}
registry.register("zhihu", ZhihuPublisher("zhihu", ZHIHU_CONFIG))