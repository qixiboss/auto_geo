# -*- coding: utf-8 -*-
"""
æ–‡ç« æ”¶é›†é€‚é…å™¨åŸºç±»
ç”¨é€‚é…å™¨æ¨¡å¼å®ç°å„å¹³å°æ”¶é›†ï¼Œéµå¾ªå¼€é—­åŸåˆ™ï¼
"""

import asyncio
import random
from abc import ABC, abstractmethod
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from playwright.async_api import Page, BrowserContext
from loguru import logger


@dataclass
class CollectedArticle:
    """æ”¶é›†åˆ°çš„æ–‡ç« æ•°æ®ç»“æ„"""
    title: str
    url: str
    content: str
    likes: int = 0
    reads: int = 0
    comments: int = 0
    author: str = ""
    platform: str = ""
    publish_time: str = ""


class BaseCollector(ABC):
    """
    åŸºç¡€æ–‡ç« æ”¶é›†é€‚é…å™¨
    æ³¨æ„ï¼šæ‰€æœ‰å¹³å°æ”¶é›†å™¨éƒ½è¦ç»§æ‰¿è¿™ä¸ªç±»ï¼
    """

    def __init__(self, platform_id: str, config: Dict[str, Any]):
        self.platform_id = platform_id
        self.config = config
        self.name = config.get("name", platform_id)
        self.search_url = config.get("search_url", "")
        self.min_likes = config.get("min_likes", 100)
        self.min_reads = config.get("min_reads", 1000)

    @abstractmethod
    async def search(self, page: Page, keyword: str) -> List[Dict[str, Any]]:
        """
        æœç´¢å…³é”®è¯ç›¸å…³æ–‡ç« 

        Args:
            page: Playwright Pageå¯¹è±¡
            keyword: æœç´¢å…³é”®è¯

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨ï¼š[{title, url, likes, reads, ...}, ...]
        """
        pass

    @abstractmethod
    async def extract_content(self, page: Page, url: str) -> Optional[str]:
        """
        æå–æ–‡ç« æ­£æ–‡å†…å®¹

        Args:
            page: Playwright Pageå¯¹è±¡
            url: æ–‡ç« URL

        Returns:
            æ–‡ç« æ­£æ–‡å†…å®¹
        """
        pass

    async def collect(self, page: Page, keyword: str) -> List[CollectedArticle]:
        """
        æ”¶é›†çˆ†ç«æ–‡ç« ï¼ˆä¸»æµç¨‹ï¼‰

        Args:
            page: Playwright Pageå¯¹è±¡
            keyword: æœç´¢å…³é”®è¯

        Returns:
            ç¬¦åˆæ¡ä»¶çš„æ–‡ç« åˆ—è¡¨
        """
        try:
            # 1. æœç´¢æ–‡ç« 
            search_results = await self.search(page, keyword)
            logger.info(f"[{self.name}] æœç´¢åˆ° {len(search_results)} ç¯‡æ–‡ç« ")

            # 2. ç­›é€‰çˆ†ç«æ–‡ç« 
            trending_articles = self._filter_trending(search_results)
            logger.info(f"[{self.name}] ç­›é€‰å‡º {len(trending_articles)} ç¯‡çˆ†ç«æ–‡ç« ")

            # 3. æå–æ­£æ–‡å†…å®¹
            collected = []
            for article in trending_articles:
                content = await self.extract_content(page, article["url"])
                if content:
                    collected.append(CollectedArticle(
                        title=article.get("title", ""),
                        url=article.get("url", ""),
                        content=content,
                        likes=article.get("likes", 0),
                        reads=article.get("reads", 0),
                        comments=article.get("comments", 0),
                        author=article.get("author", ""),
                        platform=self.platform_id,
                        publish_time=article.get("publish_time", "")
                    ))

            return collected

        except Exception as e:
            logger.error(f"[{self.name}] æ”¶é›†æ–‡ç« å¤±è´¥: {e}")
            return []

    def _filter_trending(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ç­›é€‰çˆ†ç«æ–‡ç« 

        ç­›é€‰é€»è¾‘ï¼šç‚¹èµæ•° > min_likes æˆ– é˜…è¯»é‡ > min_reads
        """
        trending = []
        for article in articles:
            likes = article.get("likes", 0)
            reads = article.get("reads", 0)

            if likes > self.min_likes or reads > self.min_reads:
                trending.append(article)
                logger.debug(f"[{self.name}] çˆ†ç«: {article.get('title', '')[:30]}... "
                           f"(ğŸ‘{likes}, ğŸ‘{reads})")

        return trending

    async def wait_for_selector(self, page: Page, selector: str, timeout: int = 10000) -> bool:
        """ç­‰å¾…é€‰æ‹©å™¨å‡ºç°"""
        try:
            await page.wait_for_selector(selector, timeout=timeout)
            return True
        except Exception as e:
            logger.warning(f"ç­‰å¾…é€‰æ‹©å™¨è¶…æ—¶: {selector}, {e}")
            return False

    async def navigate_to_search(self, page: Page, keyword: str) -> bool:
        """å¯¼èˆªåˆ°æœç´¢é¡µé¢"""
        try:
            search_url = self.search_url.format(keyword=keyword)
            await page.goto(search_url, wait_until="networkidle")
            logger.info(f"[{self.name}] å·²å¯¼èˆªåˆ°æœç´¢é¡µ: {keyword}")
            return True
        except Exception as e:
            logger.error(f"[{self.name}] å¯¼èˆªæœç´¢é¡µå¤±è´¥: {e}")
            return False

    async def _random_sleep(self, min_seconds: float = 2.0, max_seconds: float = 5.0):
        """éšæœºç­‰å¾…ï¼Œæ¨¡æ‹ŸçœŸäººæ“ä½œ"""
        await asyncio.sleep(random.uniform(min_seconds, max_seconds))

    async def _human_scroll(self, page: Page):
        """æ¨¡æ‹ŸçœŸäººç¼“æ…¢æ»šåŠ¨"""
        try:
            # è·å–é¡µé¢é«˜åº¦
            total_height = await page.evaluate("document.body.scrollHeight")
            viewport_height = await page.evaluate("window.innerHeight")
            current_position = 0

            # æ»šåŠ¨æœ€å¤š 3 å±æˆ–è€…åˆ°åº•éƒ¨
            max_scrolls = 3
            scroll_count = 0

            while current_position < total_height and scroll_count < max_scrolls:
                # æ¯æ¬¡æ»šåŠ¨å‰æ£€æµ‹ç™»å½•å¼¹çª—
                await self._handle_login_popup(page)

                # éšæœºæ»šåŠ¨è·ç¦»
                scroll_step = random.randint(300, 800)
                current_position += scroll_step
                
                # æ‰§è¡Œæ»šåŠ¨
                await page.evaluate(f"window.scrollTo(0, {current_position})")
                
                # éšæœºç­‰å¾…ï¼Œæ¨¡æ‹Ÿé˜…è¯»
                await self._random_sleep(0.5, 1.5)
                
                # æ›´æ–°é«˜åº¦ï¼ˆå¤„ç†åŠ¨æ€åŠ è½½ï¼‰
                new_total_height = await page.evaluate("document.body.scrollHeight")
                if new_total_height > total_height:
                    total_height = new_total_height
                    
                scroll_count += 1
                logger.debug(f"[{self.name}] æ¨¡æ‹Ÿæ»šåŠ¨ {scroll_count}/{max_scrolls}")
                    
        except Exception as e:
            logger.warning(f"[{self.name}] æ»šåŠ¨æ¨¡æ‹Ÿå¼‚å¸¸: {e}")

    async def _handle_login_popup(self, page: Page):
        """å¤„ç†ç™»å½•å¼¹çª—ä¸æ‹¦æˆª"""
        try:
            # 1. æ£€æŸ¥ URL æ˜¯å¦åŒ…å«ç™»å½•ç›¸å…³è¯
            current_url = page.url
            if "signin" in current_url or "login" in current_url:
                logger.warning(f"[{self.name}] å½“å‰ URL åŒ…å«ç™»å½•å…³é”®è¯: {current_url}")
                await self._wait_for_manual_login(page)
                return

            # 2. å¸¸è§å¼¹çª—é€‰æ‹©å™¨
            popup_selectors = [
                ".Modal-wrapper", # çŸ¥ä¹ç™»å½•å¼¹çª—
                ".login-modal", 
                ".captcha-box",
                ".sign-flow-modal", # çŸ¥ä¹ç™»å½•
                "[class*='login-modal']", # é€šç”¨ç™»å½•æ¨¡æ€æ¡†
                "[class*='LoginModal']",
                ".SignFlow", # çŸ¥ä¹
                ".Button.SignFlow-submitButton", # çŸ¥ä¹ç™»å½•æŒ‰é’®
                "iframe[src*='login']", # ç™»å½• iframe
                "#captcha-verify-image", # éªŒè¯ç 
                "div[class*='captcha']", # é€šç”¨éªŒè¯ç å®¹å™¨
                ".verify-bar-close", # éªŒè¯æ¡å…³é—­æŒ‰é’®
            ]
            
            needs_login = False
            for selector in popup_selectors:
                if await page.query_selector(selector):
                    # ç¡®ä¿æ˜¯å¯è§çš„
                    if await page.is_visible(selector):
                        needs_login = True
                        logger.warning(f"[{self.name}] å‘ç°ç™»å½•å¼¹çª—é€‰æ‹©å™¨: {selector}")
                        break
            
            # 3. æ£€æŸ¥é¡µé¢æ–‡æœ¬ï¼ˆä½œä¸ºå…œåº•ï¼‰
            if not needs_login:
                # æ£€æŸ¥æ ‡é¢˜
                title = await page.title()
                if "ç™»å½•" in title or "å®‰å…¨éªŒè¯" in title:
                     needs_login = True
                     logger.warning(f"[{self.name}] é¡µé¢æ ‡é¢˜åŒ…å«ç™»å½•å…³é”®è¯: {title}")

                # åªè·å– body æ–‡æœ¬ï¼Œé¿å…è·å–å®Œæ•´ HTML å¯¼è‡´è¿‡æ…¢
                # é™åˆ¶æ–‡æœ¬é•¿åº¦æ£€æŸ¥ï¼ŒåªæŸ¥å‰ 1000 ä¸ªå­—ç¬¦æˆ–è€…ç‰¹å®šåŒºåŸŸ
                if not needs_login:
                    try:
                        # å¿«é€Ÿæ£€æŸ¥ body çš„ textContentï¼Œå¦‚æœå¤ªé•¿å¯èƒ½ä¼šå¡
                        # ä¼˜åŒ–ï¼šåªæ£€æŸ¥ç‰¹å®šå…ƒç´ æ˜¯å¦å­˜åœ¨æ–‡æœ¬
                        login_keywords = ["ç™»å½•åæŸ¥çœ‹æ›´å¤š", "è¯·ç™»å½•", "æ‰«ç ç™»å½•", "éªŒè¯ç ", "å®‰å…¨éªŒè¯", "æ³¨å†Œ/ç™»å½•", "ä¾æ¬¡ç‚¹å‡»", "æ‹–åŠ¨æ»‘å—"]
                        
                        # ä½¿ç”¨ evaluate å¿«é€Ÿåœ¨æµè§ˆå™¨ç«¯æ£€æŸ¥ï¼Œå‡å°‘ä¼ è¾“
                        js_check = """
                            () => {
                                const text = document.body.innerText;
                                const keywords = ["ç™»å½•åæŸ¥çœ‹æ›´å¤š", "è¯·ç™»å½•", "æ‰«ç ç™»å½•", "éªŒè¯ç ", "å®‰å…¨éªŒè¯", "æ³¨å†Œ/ç™»å½•", "ä¾æ¬¡ç‚¹å‡»", "æ‹–åŠ¨æ»‘å—"];
                                return keywords.some(k => text.includes(k));
                            }
                        """
                        if await page.evaluate(js_check):
                             # å†æ¬¡ç¡®è®¤ä¸æ˜¯è¯¯æŠ¥ï¼ˆæ¯”å¦‚æ–‡ç« å†…å®¹é‡Œæœ‰è¿™äº›è¯ï¼‰
                             # è¿™é‡Œå‡è®¾å¦‚æœåŒ…å«è¿™äº›è¯ï¼Œå¤§æ¦‚ç‡æ˜¯æ‹¦æˆªæç¤º
                             needs_login = True
                             logger.warning(f"[{self.name}] é¡µé¢æ–‡æœ¬åŒ…å«ç™»å½•å…³é”®è¯")
                    except Exception:
                        pass

            if needs_login:
                await self._wait_for_manual_login(page)
                
        except Exception as e:
            # è¿™é‡Œçš„å¼‚å¸¸ä¸åº”è¯¥é˜»æ–­æµç¨‹ï¼Œåªæ˜¯è®°å½•æ—¥å¿—
            logger.debug(f"[{self.name}] ç™»å½•æ£€æµ‹å¼‚å¸¸: {e}")

    async def _wait_for_manual_login(self, page: Page):
        """ç­‰å¾…æ‰‹åŠ¨ç™»å½•"""
        logger.warning("\n" + "!"*50)
        logger.warning(f"[{self.name}] æ£€æµ‹åˆ°ç™»å½•å¼¹çª—æˆ–éªŒè¯ç ï¼")
        logger.warning("è¯·åœ¨ 45 ç§’å†…æ‰‹åŠ¨å®Œæˆç™»å½•/éªŒè¯æ“ä½œ...")
        logger.warning("!"*50 + "\n")
        
        # ç»™ç”¨æˆ· 45 ç§’æ—¶é—´æ‰‹åŠ¨æ“ä½œ
        # æ¯ 5 ç§’æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦ç™»å½•æˆåŠŸï¼ˆå¯é€‰ï¼Œè¿™é‡Œç®€å•ç­‰å¾…ï¼‰
        for i in range(9):
            await asyncio.sleep(5)
            logger.info(f"[{self.name}] å‰©ä½™ç­‰å¾…æ—¶é—´: {45 - (i+1)*5} ç§’...")
            
            # å¦‚æœå¼¹çª—æ¶ˆå¤±äº†ï¼Œæå‰ç»“æŸç­‰å¾…
            # è¿™é‡Œç®€å•å®ç°ï¼Œå‡è®¾ç”¨æˆ·æ“ä½œå®Œåå¼¹çª—ä¼šæ¶ˆå¤±
            # å®é™…ä¸Šå¾ˆéš¾é€šç”¨åˆ¤æ–­ï¼Œæ‰€ä»¥è¿˜æ˜¯ç¡¬ç­‰å¾…æ¯”è¾ƒç¨³å¦¥
            
        logger.info(f"[{self.name}] æ‰‹åŠ¨æ“ä½œæ—¶é—´ç»“æŸï¼Œç»§ç»­æ‰§è¡Œ...")


class CollectorRegistry:
    """
    æ”¶é›†å™¨æ³¨å†Œè¡¨
    ç”¨è¿™ä¸ªæ¥ç®¡ç†æ‰€æœ‰å¹³å°çš„æ”¶é›†å™¨ï¼
    """

    def __init__(self):
        self._collectors: Dict[str, BaseCollector] = {}

    def register(self, platform_id: str, collector: BaseCollector):
        """æ³¨å†Œæ”¶é›†å™¨"""
        self._collectors[platform_id] = collector
        logger.info(f"æ”¶é›†å™¨å·²æ³¨å†Œ: {platform_id}")

    def get(self, platform_id: str) -> Optional[BaseCollector]:
        """è·å–æ”¶é›†å™¨"""
        return self._collectors.get(platform_id)

    def list_all(self) -> Dict[str, BaseCollector]:
        """åˆ—å‡ºæ‰€æœ‰æ”¶é›†å™¨"""
        return self._collectors.copy()


# å…¨å±€æ³¨å†Œè¡¨
collector_registry = CollectorRegistry()


def get_collector(platform_id: str) -> Optional[BaseCollector]:
    """è·å–å¹³å°æ”¶é›†å™¨"""
    return collector_registry.get(platform_id)


def list_collectors() -> Dict[str, BaseCollector]:
    """åˆ—å‡ºæ‰€æœ‰æ”¶é›†å™¨"""
    return collector_registry.list_all()
