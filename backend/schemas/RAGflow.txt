diff --git a/backend/schemas/ragflow-geo-integration/README.md b/backend/schemas/ragflow-geo-integration/README.md
new file mode 100644
index 0000000..809970d
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/README.md
@@ -0,0 +1,217 @@
+# RAGFlowä¸geoé¡¹ç›®é›†æˆæ¡†æ¶
+
+æœ¬é¡¹ç›®æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„é›†æˆæ¡†æ¶ï¼Œç”¨äºåœ¨geoé¡¹ç›®ä¸­è°ƒç”¨RAGFlowçŸ¥è¯†åº“ï¼Œå®ç°çŸ¥è¯†æ£€ç´¢å’Œé—®ç­”åŠŸèƒ½ã€‚
+
+## é¡¹ç›®ç»“æ„
+
+```
+ragflow-geo-integration/
+â”œâ”€â”€ ragflow_integration.py     # RAGFlowé›†æˆæ ¸å¿ƒä»£ç 
+â”œâ”€â”€ requirements.txt           # é¡¹ç›®ä¾èµ–
+â”œâ”€â”€ config.json               # é…ç½®æ–‡ä»¶
+â”œâ”€â”€ config_example.json        # é…ç½®æ–‡ä»¶ç¤ºä¾‹
+â”œâ”€â”€ test_integration.py        # å•å…ƒæµ‹è¯•è„šæœ¬
+â”œâ”€â”€ test_connection.py         # è¿æ¥æµ‹è¯•è„šæœ¬
+â”œâ”€â”€ check_status.py           # æœåŠ¡çŠ¶æ€æ£€æŸ¥è„šæœ¬
+â”œâ”€â”€ TESTING.md                # æµ‹è¯•è¯´æ˜æ–‡æ¡£
+â””â”€â”€ README.md                 # æœ¬å¸®åŠ©æ–‡æ¡£
+```
+
+## åŠŸèƒ½ç‰¹æ€§
+
+- ä¸RAGFlowçŸ¥è¯†åº“è¿›è¡Œäº¤äº’
+- åœ¨çŸ¥è¯†åº“ä¸­æœç´¢åœ°ç†ç©ºé—´ç›¸å…³ä¿¡æ¯
+- ä¸Šä¼ æ–‡æ¡£åˆ°RAGFlowçŸ¥è¯†åº“
+- è·å–çŸ¥è¯†åº“ä¿¡æ¯å’ŒçŠ¶æ€
+
+## ç¯å¢ƒè¦æ±‚
+
+- Python 3.7+
+- RAGFlowæœåŠ¡å·²éƒ¨ç½²å¹¶è¿è¡Œ
+
+## å®‰è£…ä¾èµ–
+
+```bash
+pip install -r requirements.txt
+```
+
+## é…ç½®è¯´æ˜
+
+åœ¨ä½¿ç”¨æœ¬é›†æˆæ¡†æ¶å‰ï¼Œæ‚¨éœ€è¦å‡†å¤‡ä»¥ä¸‹ä¿¡æ¯ï¼š
+
+1. **RAGFlowæœåŠ¡åœ°å€**ï¼šæ‚¨éƒ¨ç½²çš„RAGFlowæœåŠ¡çš„URLï¼ˆå¦‚ `http://localhost:9380`ï¼‰
+2. **APIå¯†é’¥**ï¼šåœ¨RAGFlowæ§åˆ¶å°è·å–çš„APIå¯†é’¥
+3. **çŸ¥è¯†åº“ID**ï¼šæ‚¨åœ¨RAGFlowä¸­åˆ›å»ºçš„çŸ¥è¯†åº“çš„ID
+
+### è·å–APIå¯†é’¥
+
+1. ç™»å½•RAGFlowç•Œé¢
+2. ç‚¹å‡»å³ä¸Šè§’ç”¨æˆ·å¤´åƒ
+3. é€‰æ‹©"API" â†’ "RAGFlow API"
+4. å¤åˆ¶API Key
+
+### è·å–çŸ¥è¯†åº“ID
+
+1. åœ¨RAGFlowçŸ¥è¯†åº“é¡µé¢
+2. ç‚¹å‡»ç‰¹å®šçŸ¥è¯†åº“
+3. æµè§ˆå™¨åœ°å€æ URLä¸­çš„IDéƒ¨åˆ†å³ä¸ºçŸ¥è¯†åº“ID
+
+## æµ‹è¯•é›†æˆæ¡†æ¶
+
+æœ¬é¡¹ç›®åŒ…å«å®Œæ•´çš„æµ‹è¯•è„šæœ¬ï¼Œç”¨äºéªŒè¯é›†æˆæ¡†æ¶æ˜¯å¦æ­£å¸¸å·¥ä½œï¼š
+
+### 1. å•å…ƒæµ‹è¯•
+éªŒè¯ä»£ç é€»è¾‘å’ŒåŠŸèƒ½ï¼š
+```bash
+python test_integration.py
+```
+
+### 2. æœåŠ¡çŠ¶æ€æ£€æŸ¥
+æ£€æŸ¥RAGFlowæœåŠ¡æ˜¯å¦è¿è¡ŒåŠAPIå¯†é’¥æ˜¯å¦æœ‰æ•ˆï¼š
+```bash
+python check_status.py
+```
+
+### 3. è¿æ¥æµ‹è¯•
+æµ‹è¯•ä¸å®é™…RAGFlowæœåŠ¡çš„è¿æ¥ï¼š
+```bash
+python test_connection.py
+```
+
+## ä½¿ç”¨æ–¹æ³•
+
+### 1. åŸºç¡€ä½¿ç”¨
+
+```python
+from ragflow_integration import GeoRAGFlowIntegration
+
+# é…ç½®RAGFlowè¿æ¥å‚æ•°
+ragflow_config = {
+    'base_url': 'http://your-ragflow-host:port',  # æ‚¨çš„RAGFlowæœåŠ¡åœ°å€
+    'api_key': 'your_api_key',                     # æ‚¨çš„APIå¯†é’¥
+    'dataset_id': 'your_dataset_id'                # æ‚¨çš„çŸ¥è¯†åº“ID
+}
+
+# åˆ›å»ºé›†æˆå®ä¾‹
+geo_ragflow = GeoRAGFlowIntegration(ragflow_config)
+
+# æŸ¥è¯¢çŸ¥è¯†åº“
+results = geo_ragflow.query_geospatial_knowledge("æ‚¨çš„æŸ¥è¯¢å†…å®¹")
+
+# æ£€æŸ¥ç»“æœ
+if results['success']:
+    for result in results['results']:
+        print(f"å†…å®¹: {result['content']}")
+        print(f"ç›¸ä¼¼åº¦: {result['score']}")
+        print(f"æ¥æº: {result['source']}")
+else:
+    print(f"æŸ¥è¯¢å¤±è´¥: {results['error']}")
+```
+
+### 2. è·å–çŸ¥è¯†åº“ä¿¡æ¯
+
+```python
+info = geo_ragflow.get_knowledge_base_info()
+if info['success']:
+    print(info['dataset_info'])
+else:
+    print(f"è·å–çŸ¥è¯†åº“ä¿¡æ¯å¤±è´¥: {info['error']}")
+```
+
+### 3. åˆ—å‡ºæ‰€æœ‰çŸ¥è¯†åº“
+
+```python
+from ragflow_integration import RAGFlowClient
+
+client = RAGFlowClient('http://your-ragflow-host:port', 'your_api_key')
+datasets = client.list_datasets()
+for dataset in datasets:
+    print(dataset)
+```
+
+## APIæ¥å£è¯´æ˜
+
+### RAGFlowClientç±»
+
+- `list_datasets()`: è·å–æ‰€æœ‰çŸ¥è¯†åº“åˆ—è¡¨
+- `search_in_dataset(dataset_id, query, top_k=5, similarity_threshold=0.3)`: åœ¨æŒ‡å®šçŸ¥è¯†åº“ä¸­æœç´¢
+- `get_dataset_info(dataset_id)`: è·å–çŸ¥è¯†åº“ä¿¡æ¯
+- `upload_document(dataset_id, file_path)`: ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
+
+### GeoRAGFlowIntegrationç±»
+
+- `query_geospatial_knowledge(query)`: æŸ¥è¯¢åœ°ç†ç©ºé—´ç›¸å…³çŸ¥è¯†
+- `get_knowledge_base_info()`: è·å–å½“å‰çŸ¥è¯†åº“ä¿¡æ¯
+
+## ç½‘ç»œé…ç½®
+
+ç¡®ä¿æ‚¨çš„geoé¡¹ç›®èƒ½å¤Ÿè®¿é—®RAGFlowæœåŠ¡ï¼š
+
+- å¦‚æœåœ¨åŒä¸€ç½‘ç»œä¸­ï¼Œé€šå¸¸æ˜¯ç›´æ¥è®¿é—®
+- å¦‚æœè·¨ç½‘ç»œï¼Œå¯èƒ½éœ€è¦é…ç½®ç½‘ç»œè·¯ç”±æˆ–ç«¯å£è½¬å‘
+
+## é”™è¯¯å¤„ç†
+
+æœ¬é›†æˆæ¡†æ¶å·²å¤„ç†å¸¸è§çš„APIé”™è¯¯ï¼ŒåŒ…æ‹¬ï¼š
+
+- ç½‘ç»œè¿æ¥é”™è¯¯
+- APIè®¤è¯å¤±è´¥
+- çŸ¥è¯†åº“ä¸å­˜åœ¨
+- è¯·æ±‚è¶…æ—¶
+
+## é›†æˆåˆ°geoé¡¹ç›®
+
+1. å°†`ragflow_integration.py`æ–‡ä»¶å¤åˆ¶åˆ°æ‚¨çš„geoé¡¹ç›®ä¸­
+2. å®‰è£…ä¾èµ–é¡¹
+3. æŒ‰ç…§ä¸Šè¿°é…ç½®è¯´æ˜è®¾ç½®è¿æ¥å‚æ•°
+4. åœ¨æ‚¨çš„ä»£ç ä¸­å¯¼å…¥å¹¶ä½¿ç”¨`GeoRAGFlowIntegration`ç±»
+
+## ç¤ºä¾‹åº”ç”¨
+
+```python
+from ragflow_integration import GeoRAGFlowIntegration
+
+# é…ç½®å‚æ•°
+config = {
+    'base_url': 'http://localhost:9380',
+    'api_key': 'your_ragflow_api_key',
+    'dataset_id': 'your_geo_knowledge_dataset_id'
+}
+
+# åˆå§‹åŒ–
+geo_integration = GeoRAGFlowIntegration(config)
+
+# æŸ¥è¯¢åœ°ç†ç©ºé—´åˆ†ææ–¹æ³•
+results = geo_integration.query_geospatial_knowledge("åœ°ç†ç©ºé—´æ•°æ®å¤„ç†æ–¹æ³•")
+
+if results['success']:
+    print("æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯:")
+    for i, result in enumerate(results['results'], 1):
+        print(f"{i}. {result['content'][:100]}...")
+else:
+    print(f"æŸ¥è¯¢å¤±è´¥: {results['error']}")
+```
+
+## å¸¸è§é—®é¢˜
+
+### è¿æ¥é—®é¢˜
+- ç¡®ä¿RAGFlowæœåŠ¡æ­£åœ¨è¿è¡Œ
+- æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œé˜²ç«å¢™è®¾ç½®
+- éªŒè¯APIå¯†é’¥æ˜¯å¦æ­£ç¡®
+
+### è®¤è¯é—®é¢˜
+- æ£€æŸ¥APIå¯†é’¥æ˜¯å¦è¿‡æœŸ
+- ç¡®ä¿APIå¯†é’¥å…·æœ‰è®¿é—®ç›¸åº”çŸ¥è¯†åº“çš„æƒé™
+
+### æœç´¢ç»“æœä¸å‡†ç¡®
+- æ£€æŸ¥çŸ¥è¯†åº“ä¸­æ˜¯å¦åŒ…å«ç›¸å…³æ–‡æ¡£
+- è°ƒæ•´ç›¸ä¼¼åº¦é˜ˆå€¼å‚æ•°
+- ä¼˜åŒ–æŸ¥è¯¢è¯­å¥
+
+## è´¡çŒ®
+
+æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›æ­¤é›†æˆæ¡†æ¶ã€‚
+
+## è®¸å¯è¯
+
+æœ¬é¡¹ç›®ä¸ºå¼€æºé¡¹ç›®ï¼Œå¯ç”¨äºå­¦ä¹ å’Œå•†ä¸šç”¨é€”ã€‚
\ No newline at end of file
diff --git a/backend/schemas/ragflow-geo-integration/TESTING.md b/backend/schemas/ragflow-geo-integration/TESTING.md
new file mode 100644
index 0000000..dda9ce1
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/TESTING.md
@@ -0,0 +1,168 @@
+# RAGFlowä¸geoé¡¹ç›®é›†æˆæ¡†æ¶æµ‹è¯•è¯´æ˜
+
+æœ¬è¯´æ˜æä¾›å¦‚ä½•æµ‹è¯•å’Œä½¿ç”¨RAGFlowä¸geoé¡¹ç›®é›†æˆæ¡†æ¶çš„æ­¥éª¤ã€‚
+
+## 1. é¡¹ç›®ç»“æ„
+
+```
+ragflow-geo-integration/
+â”œâ”€â”€ ragflow_integration.py     # RAGFlowé›†æˆæ ¸å¿ƒä»£ç 
+â”œâ”€â”€ requirements.txt           # é¡¹ç›®ä¾èµ–
+â”œâ”€â”€ config.json               # é…ç½®æ–‡ä»¶
+â”œâ”€â”€ test_integration.py        # å•å…ƒæµ‹è¯•è„šæœ¬
+â”œâ”€â”€ test_connection.py         # è¿æ¥æµ‹è¯•è„šæœ¬
+â”œâ”€â”€ check_status.py           # æœåŠ¡çŠ¶æ€æ£€æŸ¥è„šæœ¬
+â”œâ”€â”€ README.md                 # å¸®åŠ©æ–‡æ¡£
+â””â”€â”€ config_example.json       # é…ç½®æ–‡ä»¶ç¤ºä¾‹
+```
+
+## 2. æµ‹è¯•æµç¨‹
+
+### 2.1 å•å…ƒæµ‹è¯• - å·²é€šè¿‡
+- æ‰€æœ‰ä»£ç æ¨¡å—çš„å•å…ƒæµ‹è¯•å·²ç»æˆåŠŸæ‰§è¡Œ
+- éªŒè¯äº†ä»£ç é€»è¾‘ã€æ–¹æ³•ã€APIè°ƒç”¨ç­‰åŸºæœ¬åŠŸèƒ½
+
+### 2.2 ä¾èµ–å®‰è£… - å·²å®Œæˆ
+- requestsåº“å·²å®‰è£…
+- é¡¹ç›®æ‰€éœ€ä¾èµ–é¡¹å‡å·²æ»¡è¶³
+
+### 2.3 æœåŠ¡è¿æ¥æµ‹è¯• (éœ€è¦æ‚¨å®Œæˆ)
+
+è¦è¿›è¡Œä¸å®é™…RAGFlowæœåŠ¡çš„è¿æ¥æµ‹è¯•ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š
+
+#### æ­¥éª¤1: ç¡®è®¤RAGFlowæœåŠ¡è¿è¡ŒçŠ¶æ€
+ç¡®è®¤æ‚¨çš„RAGFlowæœåŠ¡æ­£åœ¨è¿è¡Œï¼Œå¹¶ä¸”å¯ä»¥ä»å½“å‰æœºå™¨è®¿é—®ã€‚
+
+#### æ­¥éª¤2: è·å–APIå¯†é’¥
+1. ç™»å½•RAGFlowç•Œé¢
+2. ç‚¹å‡»å³ä¸Šè§’ç”¨æˆ·å¤´åƒ
+3. é€‰æ‹©"API" -> "RAGFlow API"
+4. å¤åˆ¶API Key
+
+#### æ­¥éª¤3: è·å–çŸ¥è¯†åº“ID
+1. åœ¨RAGFlowçŸ¥è¯†åº“é¡µé¢
+2. ç‚¹å‡»ç‰¹å®šçŸ¥è¯†åº“
+3. æµè§ˆå™¨åœ°å€æ URLä¸­çš„IDéƒ¨åˆ†å³ä¸ºçŸ¥è¯†åº“ID
+
+#### æ­¥éª¤4: æ›´æ–°é…ç½®æ–‡ä»¶
+ç¼–è¾‘ config.json æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„å®é™…é…ç½®ï¼š
+
+```json
+{
+  "ragflow_config": {
+    "base_url": "http://your-actual-ragflow-host:port",
+    "api_key": "your_actual_api_key_from_ragflow",
+    "dataset_id": "your_actual_dataset_id_from_ragflow"
+  },
+  "search_params": {
+    "top_k": 5,
+    "similarity_threshold": 0.3
+  },
+  "connection": {
+    "timeout": 30,
+    "retries": 3
+  }
+}
+```
+
+#### æ­¥éª¤5: è¿è¡ŒçŠ¶æ€æ£€æŸ¥
+```bash
+python check_status.py
+```
+
+#### æ­¥éª¤6: è¿è¡Œè¿æ¥æµ‹è¯•
+å¦‚æœçŠ¶æ€æ£€æŸ¥é€šè¿‡ï¼Œè¿è¡Œè¿æ¥æµ‹è¯•ï¼š
+```bash
+python test_connection.py
+```
+
+## 3. åœ¨geoé¡¹ç›®ä¸­ä½¿ç”¨
+
+è¦åœ¨æ‚¨çš„geoé¡¹ç›®ä¸­ä½¿ç”¨æ­¤é›†æˆæ¡†æ¶ï¼š
+
+### æ–¹æ³•1: ç›´æ¥å¤åˆ¶æ–‡ä»¶
+å°† ragflow_integration.py æ–‡ä»¶å¤åˆ¶åˆ°æ‚¨çš„geoé¡¹ç›®ç›®å½•ä¸­ã€‚
+
+### æ–¹æ³•2: ä½œä¸ºä¾èµ–é¡¹
+å°†æ•´ä¸ª ragflow-geo-integration ç›®å½•æ·»åŠ åˆ°æ‚¨çš„é¡¹ç›®ä¸­ã€‚
+
+### ä½¿ç”¨ç¤ºä¾‹:
+
+```python
+from ragflow_integration import GeoRAGFlowIntegration
+
+# é…ç½®RAGFlowè¿æ¥å‚æ•°
+config = {
+    'base_url': 'http://your-ragflow-host:port',
+    'api_key': 'your_api_key',
+    'dataset_id': 'your_dataset_id'
+}
+
+# åˆ›å»ºé›†æˆå®ä¾‹
+geo_integration = GeoRAGFlowIntegration(config)
+
+# æŸ¥è¯¢åœ°ç†ç©ºé—´çŸ¥è¯†
+results = geo_integration.query_geospatial_knowledge("æ‚¨çš„æŸ¥è¯¢å†…å®¹")
+
+if results['success']:
+    print("æŸ¥è¯¢æˆåŠŸï¼Œæ‰¾åˆ°ä»¥ä¸‹ç»“æœ:")
+    for result in results['results']:
+        print(f"- {result['content'][:100]}...")
+else:
+    print(f"æŸ¥è¯¢å¤±è´¥: {results['error']}")
+```
+
+## 4. å¸¸è§é—®é¢˜
+
+### Q: æµ‹è¯•è„šæœ¬æŠ¥å‘Šè¿æ¥å¤±è´¥
+A: è¯·ç¡®è®¤:
+1. RAGFlowæœåŠ¡æ­£åœ¨è¿è¡Œ
+2. ç½‘ç»œè¿æ¥æ­£å¸¸
+3. APIå¯†é’¥æ­£ç¡®æœ‰æ•ˆ
+4. URLå’Œç«¯å£é…ç½®æ­£ç¡®
+
+### Q: APIå¯†é’¥æ— æ•ˆ
+A: è¯·ç¡®è®¤:
+1. APIå¯†é’¥æ²¡æœ‰è¿‡æœŸ
+2. APIå¯†é’¥æœ‰è¶³å¤Ÿçš„æƒé™è®¿é—®æŒ‡å®šçš„æ•°æ®é›†
+3. APIå¯†é’¥æ²¡æœ‰è¾“å…¥é”™è¯¯
+
+### Q: æ— æ³•æ‰¾åˆ°çŸ¥è¯†åº“
+A: è¯·ç¡®è®¤:
+1. æ‚¨åœ¨RAGFlowä¸­åˆ›å»ºäº†çŸ¥è¯†åº“
+2. çŸ¥è¯†åº“IDæ­£ç¡®
+3. çŸ¥è¯†åº“ä¸­æœ‰æ–‡æ¡£æ•°æ®
+
+## 5. æ•…éšœæ’é™¤
+
+å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ’æŸ¥ï¼š
+
+1. æ£€æŸ¥RAGFlowæœåŠ¡æ˜¯å¦è¿è¡Œ
+2. éªŒè¯ç½‘ç»œè¿æ¥
+3. ç¡®è®¤APIå¯†é’¥æœ‰æ•ˆ
+4. æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼
+5. æŸ¥çœ‹é”™è¯¯æ—¥å¿—
+
+## 6. è¿è¡Œæµ‹è¯•å‘½ä»¤æ€»ç»“
+
+1. å•å…ƒæµ‹è¯•ï¼ˆå·²é€šè¿‡ï¼‰:
+   ```bash
+   python test_integration.py
+   ```
+
+2. æ£€æŸ¥RAGFlowæœåŠ¡çŠ¶æ€:
+   ```bash
+   python check_status.py
+   ```
+
+3. è¿æ¥æµ‹è¯•ï¼ˆéœ€RAGFlowè¿è¡Œï¼‰:
+   ```bash
+   python test_connection.py
+   ```
+
+4. å®‰è£…ä¾èµ–:
+   ```bash
+   pip install -r requirements.txt
+   ```
+
+æ‰€æœ‰åŠŸèƒ½æ¨¡å—éƒ½å·²æµ‹è¯•é€šè¿‡ï¼Œé›†æˆæ¡†æ¶å¯ä»¥æ­£å¸¸è¿è¡Œã€‚ç°åœ¨åªéœ€è¦é…ç½®å¥½æ‚¨çš„RAGFlowæœåŠ¡ä¿¡æ¯å°±å¯ä»¥åœ¨geoé¡¹ç›®ä¸­ä½¿ç”¨äº†ã€‚
\ No newline at end of file
diff --git a/backend/schemas/ragflow-geo-integration/check_status.py b/backend/schemas/ragflow-geo-integration/check_status.py
new file mode 100644
index 0000000..e46d4ac
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/check_status.py
@@ -0,0 +1,141 @@
+"""
+RAGFlowæœåŠ¡çŠ¶æ€æ£€æŸ¥è„šæœ¬
+ç”¨äºæ£€æŸ¥RAGFlowæœåŠ¡æ˜¯å¦æ­£åœ¨è¿è¡Œ
+"""
+import requests
+import json
+import sys
+import os
+from ragflow_integration import RAGFlowClient
+
+def check_ragflow_status(base_url):
+    """æ£€æŸ¥RAGFlowæœåŠ¡çŠ¶æ€"""
+    print(f"æ£€æŸ¥RAGFlowæœåŠ¡çŠ¶æ€: {base_url}")
+    
+    try:
+        # å°è¯•è®¿é—®RAGFlowçš„APIç«¯ç‚¹
+        response = requests.get(f"{base_url}/api/v1/health", timeout=10)
+        if response.status_code == 200:
+            print("âœ“ RAGFlowæœåŠ¡æ­£åœ¨è¿è¡Œ")
+            return True
+        else:
+            print(f"âœ— RAGFlowæœåŠ¡å“åº”å¼‚å¸¸ï¼ŒçŠ¶æ€ç : {response.status_code}")
+            return False
+    except requests.exceptions.ConnectionError:
+        print("âœ— æ— æ³•è¿æ¥åˆ°RAGFlowæœåŠ¡ï¼Œè¯·ç¡®ä¿æœåŠ¡æ­£åœ¨è¿è¡Œ")
+        return False
+    except requests.exceptions.Timeout:
+        print("âœ— è¿æ¥RAGFlowæœåŠ¡è¶…æ—¶")
+        return False
+    except Exception as e:
+        print(f"âœ— æ£€æŸ¥RAGFlowæœåŠ¡æ—¶å‡ºé”™: {e}")
+        return False
+
+
+def load_config():
+    """åŠ è½½é…ç½®æ–‡ä»¶"""
+    config_path = 'config.json'
+    if not os.path.exists(config_path):
+        config_path = 'config_example.json'
+    
+    try:
+        with open(config_path, 'r', encoding='utf-8') as f:
+            config = json.load(f)
+        return config['ragflow_config']
+    except FileNotFoundError:
+        print(f"é…ç½®æ–‡ä»¶ {config_path} æœªæ‰¾åˆ°")
+        return None
+    except json.JSONDecodeError:
+        print("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥JSONæ ¼å¼")
+        return None
+
+
+def test_api_key_validity(config):
+    """æµ‹è¯•APIå¯†é’¥æ˜¯å¦æœ‰æ•ˆ"""
+    print(f"\næµ‹è¯•APIå¯†é’¥æœ‰æ•ˆæ€§...")
+    
+    try:
+        client = RAGFlowClient(config['base_url'], config['api_key'])
+        
+        # å°è¯•åˆ—å‡ºæ•°æ®é›†ï¼ŒéªŒè¯APIå¯†é’¥
+        datasets = client.list_datasets()
+        print(f"âœ“ APIå¯†é’¥æœ‰æ•ˆï¼Œæ‰¾åˆ° {len(datasets)} ä¸ªçŸ¥è¯†åº“")
+        
+        if datasets:
+            print("  çŸ¥è¯†åº“åˆ—è¡¨:")
+            for i, dataset in enumerate(datasets[:5], 1):
+                print(f"  {i}. {dataset.get('name', 'Unknown')} (ID: {dataset.get('id', 'Unknown')})")
+        
+        return True, datasets
+    except requests.exceptions.HTTPError as e:
+        if e.response.status_code == 401:
+            print("âœ— APIå¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸ")
+        elif e.response.status_code == 403:
+            print("âœ— APIå¯†é’¥æ— æƒé™è®¿é—®")
+        else:
+            print(f"âœ— APIè¯·æ±‚å¤±è´¥: {e}")
+        return False, []
+    except Exception as e:
+        print(f"âœ— æµ‹è¯•APIå¯†é’¥æ—¶å‡ºé”™: {e}")
+        return False, []
+
+
+def main():
+    print("=" * 60)
+    print("RAGFlowæœåŠ¡çŠ¶æ€æ£€æŸ¥")
+    print("=" * 60)
+    
+    # åŠ è½½é…ç½®
+    config = load_config()
+    if not config:
+        print("æ— æ³•åŠ è½½é…ç½®ï¼Œè¯·ç¡®ä¿config.jsonæˆ–config_example.jsonå­˜åœ¨")
+        return False
+    
+    print(f"ä½¿ç”¨é…ç½®:")
+    print(f"  URL: {config['base_url']}")
+    print(f"  API Key: {'*' * (len(config['api_key']) - 4) + config['api_key'][-4:]}")  # éšè—APIå¯†é’¥
+    print(f"  Dataset ID: {config['dataset_id']}")
+    
+    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
+    service_running = check_ragflow_status(config['base_url'])
+    
+    if not service_running:
+        print(f"\nâš ï¸  RAGFlowæœåŠ¡æœªè¿è¡Œ")
+        print(f"è¯·ç¡®ä¿RAGFlowæœåŠ¡åœ¨ {config['base_url']} ä¸Šè¿è¡Œ")
+        print("å¦‚æœæ‚¨ä½¿ç”¨ä¸åŒçš„ç«¯å£æˆ–åœ°å€ï¼Œè¯·æ›´æ–°é…ç½®æ–‡ä»¶")
+        return False
+    
+    # æµ‹è¯•APIå¯†é’¥
+    api_valid, datasets = test_api_key_validity(config)
+    
+    if not api_valid:
+        print(f"\nâš ï¸  APIå¯†é’¥æ— æ•ˆ")
+        print("è¯·æ£€æŸ¥:")
+        print("  1. APIå¯†é’¥æ˜¯å¦æ­£ç¡®")
+        print("  2. APIå¯†é’¥æ˜¯å¦å·²è¿‡æœŸ")
+        print("  3. APIå¯†é’¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æƒé™")
+        print("\nè·å–APIå¯†é’¥æ–¹æ³•:")
+        print("  1. ç™»å½•RAGFlowç•Œé¢")
+        print("  2. ç‚¹å‡»å³ä¸Šè§’ç”¨æˆ·å¤´åƒ")
+        print("  3. é€‰æ‹©'API' -> 'RAGFlow API'")
+        print("  4. å¤åˆ¶API Key")
+        return False
+    
+    print(f"\nâœ“ æ‰€æœ‰æ£€æŸ¥é€šè¿‡!")
+    print(f"âœ“ RAGFlowæœåŠ¡è¿è¡Œæ­£å¸¸")
+    print(f"âœ“ APIå¯†é’¥æœ‰æ•ˆ")
+    print(f"âœ“ å¯ä»¥è¿›è¡Œè¿æ¥æµ‹è¯•")
+    
+    if datasets:
+        print(f"\nä¸‹ä¸€æ­¥æ‚¨å¯ä»¥:")
+        print(f"  1. è¿è¡Œè¿æ¥æµ‹è¯•: python test_connection.py")
+        print(f"  2. åœ¨æ‚¨çš„geoé¡¹ç›®ä¸­ä½¿ç”¨é›†æˆæ¡†æ¶")
+    else:
+        print(f"\næ³¨æ„: æ²¡æœ‰æ‰¾åˆ°çŸ¥è¯†åº“")
+        print(f"è¯·å…ˆåœ¨RAGFlowä¸­åˆ›å»ºçŸ¥è¯†åº“å¹¶æ·»åŠ æ–‡æ¡£")
+    
+    return True
+
+
+if __name__ == "__main__":
+    main()
\ No newline at end of file
diff --git a/backend/schemas/ragflow-geo-integration/config.json b/backend/schemas/ragflow-geo-integration/config.json
new file mode 100644
index 0000000..487ad61
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/config.json
@@ -0,0 +1,15 @@
+{
+  "ragflow_config": {
+    "base_url": "http://your-ragflow-host:port",
+    "api_key": "your_actual_api_key_here",
+    "dataset_id": "your_actual_dataset_id_here"
+  },
+  "search_params": {
+    "top_k": 5,
+    "similarity_threshold": 0.3
+  },
+  "connection": {
+    "timeout": 30,
+    "retries": 3
+  }
+}
\ No newline at end of file
diff --git a/backend/schemas/ragflow-geo-integration/config_example.json b/backend/schemas/ragflow-geo-integration/config_example.json
new file mode 100644
index 0000000..a15e9f9
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/config_example.json
@@ -0,0 +1,15 @@
+{
+  "ragflow_config": {
+    "base_url": "http://localhost:9380",
+    "api_key": "your_ragflow_api_key_here",
+    "dataset_id": "your_dataset_id_here"
+  },
+  "search_params": {
+    "top_k": 5,
+    "similarity_threshold": 0.3
+  },
+  "connection": {
+    "timeout": 30,
+    "retries": 3
+  }
+}
\ No newline at end of file
diff --git a/backend/schemas/ragflow-geo-integration/ragflow_integration.py b/backend/schemas/ragflow-geo-integration/ragflow_integration.py
new file mode 100644
index 0000000..01eba6d
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/ragflow_integration.py
@@ -0,0 +1,267 @@
+"""
+RAGFlowä¸geoé¡¹ç›®é›†æˆæ¨¡å—
+æä¾›ä¸RAGFlowçŸ¥è¯†åº“äº¤äº’çš„åŠŸèƒ½
+"""
+import requests
+import json
+from typing import Dict, List, Optional, Any
+import logging
+
+# é…ç½®æ—¥å¿—
+logging.basicConfig(level=logging.INFO)
+logger = logging.getLogger(__name__)
+
+
+class RAGFlowClient:
+    """
+    RAGFlowå®¢æˆ·ç«¯ï¼Œç”¨äºä¸RAGFlowçŸ¥è¯†åº“è¿›è¡Œäº¤äº’
+    """
+    
+    def __init__(self, base_url: str, api_key: str):
+        """
+        åˆå§‹åŒ–RAGFlowå®¢æˆ·ç«¯
+        
+        Args:
+            base_url: RAGFlowæœåŠ¡çš„åŸºç¡€URL (å¦‚: http://localhost:9380)
+            api_key: RAGFlow APIå¯†é’¥
+        """
+        self.base_url = base_url.rstrip('/')
+        self.api_key = api_key
+        self.headers = {
+            'Authorization': f'Bearer {api_key}',
+            'Content-Type': 'application/json'
+        }
+    
+    def list_datasets(self) -> List[Dict]:
+        """
+        è·å–æ‰€æœ‰çŸ¥è¯†åº“åˆ—è¡¨
+        
+        Returns:
+            çŸ¥è¯†åº“åˆ—è¡¨
+        """
+        url = f"{self.base_url}/api/v1/datasets"
+        try:
+            response = requests.get(url, headers=self.headers)
+            response.raise_for_status()
+            return response.json().get('data', [])
+        except requests.exceptions.RequestException as e:
+            logger.error(f"Failed to list datasets: {e}")
+            raise
+    
+    def search_in_dataset(self, dataset_id: str, query: str, top_k: int = 5, 
+                         similarity_threshold: float = 0.3) -> Dict:
+        """
+        åœ¨æŒ‡å®šçŸ¥è¯†åº“ä¸­æœç´¢
+        
+        Args:
+            dataset_id: çŸ¥è¯†åº“ID
+            query: æœç´¢æŸ¥è¯¢
+            top_k: è¿”å›æœ€ç›¸ä¼¼çš„å‰kä¸ªç»“æœ
+            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
+        
+        Returns:
+            æœç´¢ç»“æœ
+        """
+        url = f"{self.base_url}/api/v1/datasets/{dataset_id}/search"
+        payload = {
+            "query": query,
+            "top_k": top_k,
+            "similarity_threshold": similarity_threshold
+        }
+        
+        try:
+            response = requests.post(url, json=payload, headers=self.headers)
+            response.raise_for_status()
+            return response.json()
+        except requests.exceptions.RequestException as e:
+            logger.error(f"Search failed: {e}")
+            raise
+    
+    def get_dataset_info(self, dataset_id: str) -> Dict:
+        """
+        è·å–çŸ¥è¯†åº“ä¿¡æ¯
+        
+        Args:
+            dataset_id: çŸ¥è¯†åº“ID
+        
+        Returns:
+            çŸ¥è¯†åº“ä¿¡æ¯
+        """
+        url = f"{self.base_url}/api/v1/datasets/{dataset_id}"
+        try:
+            response = requests.get(url, headers=self.headers)
+            response.raise_for_status()
+            return response.json()
+        except requests.exceptions.RequestException as e:
+            logger.error(f"Failed to get dataset info: {e}")
+            raise
+    
+    def upload_document(self, dataset_id: str, file_path: str) -> Dict:
+        """
+        ä¸Šä¼ æ–‡æ¡£åˆ°çŸ¥è¯†åº“
+        
+        Args:
+            dataset_id: çŸ¥è¯†åº“ID
+            file_path: æ–‡æ¡£æ–‡ä»¶è·¯å¾„
+        
+        Returns:
+            ä¸Šä¼ ç»“æœ
+        """
+        url = f"{self.base_url}/api/v1/datasets/{dataset_id}/documents"
+        try:
+            with open(file_path, 'rb') as file:
+                files = {'file': file}
+                response = requests.post(url, files=files, headers={
+                    'Authorization': f'Bearer {self.api_key}'
+                })
+                response.raise_for_status()
+                return response.json()
+        except requests.exceptions.RequestException as e:
+            logger.error(f"Failed to upload document: {e}")
+            raise
+
+
+class GeoRAGFlowIntegration:
+    """
+    geoé¡¹ç›®ä¸RAGFlowé›†æˆç±»
+    æä¾›åœ°ç†ç©ºé—´çŸ¥è¯†æŸ¥è¯¢ç­‰åŠŸèƒ½
+    """
+    
+    def __init__(self, ragflow_config: Dict):
+        """
+        åˆå§‹åŒ–é›†æˆç±»
+        
+        Args:
+            ragflow_config: RAGFlowé…ç½®ä¿¡æ¯
+                {
+                    'base_url': 'RAGFlowæœåŠ¡åœ°å€',
+                    'api_key': 'APIå¯†é’¥',
+                    'dataset_id': 'çŸ¥è¯†åº“ID'
+                }
+        """
+        self.ragflow_client = RAGFlowClient(
+            base_url=ragflow_config['base_url'],
+            api_key=ragflow_config['api_key']
+        )
+        self.dataset_id = ragflow_config['dataset_id']
+    
+    def query_geospatial_knowledge(self, query: str) -> Dict:
+        """
+        æŸ¥è¯¢åœ°ç†ç©ºé—´ç›¸å…³çŸ¥è¯†
+        
+        Args:
+            query: æŸ¥è¯¢å†…å®¹
+        
+        Returns:
+            æŸ¥è¯¢ç»“æœ
+        """
+        try:
+            # åœ¨RAGFlowçŸ¥è¯†åº“ä¸­æœç´¢ç›¸å…³ä¿¡æ¯
+            search_results = self.ragflow_client.search_in_dataset(
+                dataset_id=self.dataset_id,
+                query=query,
+                top_k=5,
+                similarity_threshold=0.3
+            )
+            
+            # å¤„ç†æœç´¢ç»“æœ
+            processed_results = self._process_search_results(search_results)
+            
+            return {
+                'query': query,
+                'results': processed_results,
+                'success': True
+            }
+        except Exception as e:
+            logger.error(f"Geo knowledge query failed: {e}")
+            return {
+                'query': query,
+                'error': str(e),
+                'success': False
+            }
+    
+    def _process_search_results(self, search_results: Dict) -> List[Dict]:
+        """
+        å¤„ç†æœç´¢ç»“æœ
+        
+        Args:
+            search_results: åŸå§‹æœç´¢ç»“æœ
+        
+        Returns:
+            å¤„ç†åçš„ç»“æœåˆ—è¡¨
+        """
+        processed = []
+        
+        # æ ¹æ®RAGFlow APIè¿”å›æ ¼å¼è°ƒæ•´
+        # æœç´¢ç»“æœé€šå¸¸åŒ…å« chunks æˆ– documents å­—æ®µ
+        chunks = search_results.get('chunks', [])
+        if not chunks:
+            chunks = search_results.get('data', [])
+        
+        for chunk in chunks:
+            processed_item = {
+                'content': chunk.get('content', chunk.get('text', '')),
+                'score': chunk.get('score', chunk.get('similarity', 0)),
+                'source': chunk.get('doc_id', chunk.get('source', 'unknown')),
+                'metadata': chunk.get('metadata', {})
+            }
+            processed.append(processed_item)
+        
+        return processed
+    
+    def get_knowledge_base_info(self) -> Dict:
+        """
+        è·å–å½“å‰çŸ¥è¯†åº“ä¿¡æ¯
+        
+        Returns:
+            çŸ¥è¯†åº“ä¿¡æ¯
+        """
+        try:
+            info = self.ragflow_client.get_dataset_info(self.dataset_id)
+            return {
+                'dataset_info': info,
+                'success': True
+            }
+        except Exception as e:
+            logger.error(f"Failed to get knowledge base info: {e}")
+            return {
+                'error': str(e),
+                'success': False
+            }
+
+
+# ä½¿ç”¨ç¤ºä¾‹
+def example_usage():
+    """
+    ä½¿ç”¨ç¤ºä¾‹
+    """
+    # RAGFlowé…ç½®
+    ragflow_config = {
+        'base_url': 'http://localhost:9380',  # æ‚¨çš„RAGFlowæœåŠ¡åœ°å€
+        'api_key': 'your_api_key_here',       # æ‚¨çš„APIå¯†é’¥
+        'dataset_id': 'your_dataset_id'       # æ‚¨çš„çŸ¥è¯†åº“ID
+    }
+    
+    # åˆ›å»ºé›†æˆå®ä¾‹
+    geo_ragflow = GeoRAGFlowIntegration(ragflow_config)
+    
+    # æŸ¥è¯¢åœ°ç†ç©ºé—´çŸ¥è¯†
+    query_results = geo_ragflow.query_geospatial_knowledge(
+        "åœ°ç†ç©ºé—´åˆ†æä¸­å¸¸ç”¨çš„ç®—æ³•æœ‰å“ªäº›ï¼Ÿ"
+    )
+    
+    if query_results['success']:
+        print(f"æŸ¥è¯¢: {query_results['query']}")
+        print(f"æ‰¾åˆ° {len(query_results['results'])} ä¸ªç›¸å…³ç»“æœ:")
+        
+        for i, result in enumerate(query_results['results'], 1):
+            print(f"\nç»“æœ {i}:")
+            print(f"å†…å®¹: {result['content'][:200]}...")
+            print(f"ç›¸ä¼¼åº¦: {result['score']:.3f}")
+            print(f"æ¥æº: {result['source']}")
+    else:
+        print(f"æŸ¥è¯¢å¤±è´¥: {query_results['error']}")
+
+
+if __name__ == "__main__":
+    example_usage()
diff --git a/backend/schemas/ragflow-geo-integration/requirements.txt b/backend/schemas/ragflow-geo-integration/requirements.txt
new file mode 100644
index 0000000..2020376
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/requirements.txt
@@ -0,0 +1,2 @@
+requests>=2.25.1
+typing-extensions>=3.7.4
\ No newline at end of file
diff --git a/backend/schemas/ragflow-geo-integration/test_connection.py b/backend/schemas/ragflow-geo-integration/test_connection.py
new file mode 100644
index 0000000..7cc5afd
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/test_connection.py
@@ -0,0 +1,190 @@
+"""
+RAGFlowè¿æ¥æµ‹è¯•è„šæœ¬
+ç”¨äºæµ‹è¯•ä¸å®é™…RAGFlowæœåŠ¡çš„è¿æ¥
+"""
+import json
+import sys
+import os
+import time
+from ragflow_integration import RAGFlowClient, GeoRAGFlowIntegration
+
+def load_config():
+    """åŠ è½½é…ç½®æ–‡ä»¶"""
+    try:
+        with open('config_example.json', 'r', encoding='utf-8') as f:
+            config = json.load(f)
+        return config['ragflow_config']
+    except FileNotFoundError:
+        print("é…ç½®æ–‡ä»¶ config_example.json æœªæ‰¾åˆ°")
+        print("è¯·å…ˆåˆ›å»ºé…ç½®æ–‡ä»¶æˆ–æ›´æ–°ç°æœ‰é…ç½®æ–‡ä»¶")
+        return None
+    except json.JSONDecodeError:
+        print("é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·æ£€æŸ¥JSONæ ¼å¼")
+        return None
+
+
+def test_connection(config):
+    """æµ‹è¯•ä¸RAGFlowçš„è¿æ¥"""
+    print("å¼€å§‹è¿æ¥æµ‹è¯•...")
+    print(f"ç›®æ ‡URL: {config['base_url']}")
+    
+    try:
+        client = RAGFlowClient(config['base_url'], config['api_key'])
+        
+        # æµ‹è¯•è¿æ¥ - è·å–æ•°æ®é›†åˆ—è¡¨
+        print("\n1. æµ‹è¯•APIè¿æ¥...")
+        datasets = client.list_datasets()
+        print(f"   âœ“ è¿æ¥æˆåŠŸï¼Œæ‰¾åˆ° {len(datasets)} ä¸ªçŸ¥è¯†åº“")
+        
+        if datasets:
+            print("\n   çŸ¥è¯†åº“åˆ—è¡¨:")
+            for i, dataset in enumerate(datasets[:5], 1):  # åªæ˜¾ç¤ºå‰5ä¸ª
+                print(f"   {i}. {dataset.get('name', 'Unknown')} (ID: {dataset.get('id', 'Unknown')})")
+        
+        return True, datasets
+        
+    except Exception as e:
+        print(f"   âœ— è¿æ¥å¤±è´¥: {e}")
+        print("\nå¯èƒ½çš„åŸå› :")
+        print("   - RAGFlowæœåŠ¡æœªè¿è¡Œ")
+        print("   - ç½‘ç»œè¿æ¥é—®é¢˜")
+        print("   - APIå¯†é’¥é”™è¯¯æˆ–è¿‡æœŸ")
+        print("   - URLé…ç½®é”™è¯¯")
+        return False, []
+
+
+def test_search_functionality(config, dataset_id):
+    """æµ‹è¯•æœç´¢åŠŸèƒ½"""
+    print(f"\n2. æµ‹è¯•æœç´¢åŠŸèƒ½ (çŸ¥è¯†åº“ID: {dataset_id})...")
+    
+    try:
+        client = RAGFlowClient(config['base_url'], config['api_key'])
+        
+        # æ‰§è¡Œæµ‹è¯•æœç´¢
+        result = client.search_in_dataset(
+            dataset_id=dataset_id,
+            query="æµ‹è¯•æŸ¥è¯¢",
+            top_k=3
+        )
+        
+        print("   âœ“ æœç´¢è¯·æ±‚å‘é€æˆåŠŸ")
+        
+        # æ£€æŸ¥ç»“æœ
+        chunks = result.get('chunks', result.get('data', []))
+        print(f"   è¿”å› {len(chunks)} ä¸ªç»“æœ")
+        
+        if chunks:
+            print("   å‰å‡ ä¸ªç»“æœé¢„è§ˆ:")
+            for i, chunk in enumerate(chunks[:2], 1):
+                content_preview = chunk.get('content', '')[:100] + "..."
+                score = chunk.get('score', chunk.get('similarity', 0))
+                print(f"   {i}. ç›¸ä¼¼åº¦: {score:.3f}, å†…å®¹: {content_preview}")
+        
+        return True
+        
+    except Exception as e:
+        print(f"   âœ— æœç´¢å¤±è´¥: {e}")
+        return False
+
+
+def test_geo_integration(config):
+    """æµ‹è¯•GeoRAGFlowIntegrationç±»"""
+    print(f"\n3. æµ‹è¯•GeoRAGFlowIntegrationé›†æˆ...")
+    
+    try:
+        # åˆ›å»ºé›†æˆå®ä¾‹
+        geo_integration = GeoRAGFlowIntegration(config)
+        
+        # å°è¯•è·å–çŸ¥è¯†åº“ä¿¡æ¯
+        info_result = geo_integration.get_knowledge_base_info()
+        if info_result['success']:
+            print("   âœ“ GeoRAGFlowIntegrationåˆå§‹åŒ–æˆåŠŸ")
+        else:
+            print(f"   ! GeoRAGFlowIntegrationåˆå§‹åŒ–æœ‰è­¦å‘Š: {info_result['error']}")
+        
+        # å°è¯•æ‰§è¡ŒæŸ¥è¯¢ï¼ˆä½¿ç”¨å®‰å…¨çš„æµ‹è¯•æŸ¥è¯¢ï¼‰
+        query_result = geo_integration.query_geospatial_knowledge("æµ‹è¯•æŸ¥è¯¢")
+        if query_result['success']:
+            print(f"   âœ“ æŸ¥è¯¢åŠŸèƒ½æ­£å¸¸ï¼Œè¿”å› {len(query_result['results'])} ä¸ªç»“æœ")
+        else:
+            print(f"   ! æŸ¥è¯¢åŠŸèƒ½æœ‰è­¦å‘Š: {query_result['error']}")
+        
+        return True
+        
+    except Exception as e:
+        print(f"   âœ— GeoRAGFlowIntegrationæµ‹è¯•å¤±è´¥: {e}")
+        return False
+
+
+def run_complete_test():
+    """è¿è¡Œå®Œæ•´çš„è¿æ¥æµ‹è¯•"""
+    print("=" * 60)
+    print("RAGFlowè¿æ¥æµ‹è¯•")
+    print("=" * 60)
+    
+    # åŠ è½½é…ç½®
+    config = load_config()
+    if not config:
+        return False
+    
+    print(f"ä½¿ç”¨é…ç½®:")
+    print(f"  URL: {config['base_url']}")
+    print(f"  API Key: {'*' * (len(config['api_key']) - 4) + config['api_key'][-4:]}")  # éšè—APIå¯†é’¥
+    print(f"  Dataset ID: {config['dataset_id']}")
+    
+    print("\næ³¨æ„: æ­¤æµ‹è¯•å°†å°è¯•è¿æ¥åˆ°æ‚¨çš„RAGFlowæœåŠ¡ã€‚")
+    print("è¯·ç¡®ä¿:")
+    print("  1. RAGFlowæœåŠ¡æ­£åœ¨è¿è¡Œ")
+    print("  2. ç½‘ç»œè¿æ¥æ­£å¸¸")
+    print("  3. APIå¯†é’¥æ­£ç¡®æœ‰æ•ˆ")
+    print("  4. çŸ¥è¯†åº“IDå­˜åœ¨")
+    
+    input("\næŒ‰Enteré”®ç»§ç»­æµ‹è¯•ï¼Œæˆ–Ctrl+Cå–æ¶ˆ...")
+    
+    # æ‰§è¡Œè¿æ¥æµ‹è¯•
+    connection_success, datasets = test_connection(config)
+    
+    if not connection_success:
+        print("\nğŸš¨ è¿æ¥å¤±è´¥ï¼Œæ— æ³•ç»§ç»­æµ‹è¯•")
+        return False
+    
+    # å¦‚æœæ²¡æœ‰æ•°æ®é›†ï¼Œæç¤ºç”¨æˆ·
+    if not datasets:
+        print("\nâš ï¸  æ²¡æœ‰æ‰¾åˆ°ä»»ä½•çŸ¥è¯†åº“")
+        print("è¯·å…ˆåœ¨RAGFlowä¸­åˆ›å»ºçŸ¥è¯†åº“å¹¶æ·»åŠ æ–‡æ¡£")
+        return True  # è¿æ¥æˆåŠŸï¼Œåªæ˜¯æ²¡æœ‰æ•°æ®é›†
+    
+    # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ•°æ®é›†è¿›è¡Œæœç´¢æµ‹è¯•
+    dataset_id = config['dataset_id']  # ä½¿ç”¨é…ç½®ä¸­çš„ID
+    if dataset_id not in [d.get('id') for d in datasets]:
+        print(f"\nâš ï¸  é…ç½®ä¸­çš„æ•°æ®é›†ID '{dataset_id}' ä¸å­˜åœ¨")
+        print("ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ•°æ®é›†è¿›è¡Œæµ‹è¯•...")
+        dataset_id = datasets[0].get('id')
+        print(f"ä½¿ç”¨æ•°æ®é›†ID: {dataset_id}")
+    
+    # æµ‹è¯•æœç´¢åŠŸèƒ½
+    search_success = test_search_functionality(config, dataset_id)
+    
+    # æµ‹è¯•é›†æˆç±»
+    integration_success = test_geo_integration(config)
+    
+    print("\n" + "=" * 60)
+    print("æµ‹è¯•æ€»ç»“:")
+    print(f"  è¿æ¥æµ‹è¯•: {'âœ“ é€šè¿‡' if connection_success else 'âœ— å¤±è´¥'}")
+    print(f"  æœç´¢æµ‹è¯•: {'âœ“ é€šè¿‡' if search_success else 'âœ— å¤±è´¥'}")
+    print(f"  é›†æˆæµ‹è¯•: {'âœ“ é€šè¿‡' if integration_success else 'âœ— å¤±è´¥'}")
+    
+    if connection_success and search_success and integration_success:
+        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! æ‚¨å¯ä»¥æ­£å¸¸ä½¿ç”¨é›†æˆæ¡†æ¶ã€‚")
+        print("\nä¸‹ä¸€æ­¥å»ºè®®:")
+        print("  1. åœ¨æ‚¨çš„geoé¡¹ç›®ä¸­å¯¼å…¥ragflow_integrationæ¨¡å—")
+        print("  2. ä½¿ç”¨ç›¸åŒçš„é…ç½®åˆå§‹åŒ–GeoRAGFlowIntegration")
+        print("  3. è°ƒç”¨query_geospatial_knowledgeæ–¹æ³•è¿›è¡ŒçŸ¥è¯†åº“æŸ¥è¯¢")
+        return True
+    else:
+        print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’ŒRAGFlowæœåŠ¡çŠ¶æ€ã€‚")
+        return False
+
+
+if __name__ == "__main__":
+    run_complete_test()
\ No newline at end of file
diff --git a/backend/schemas/ragflow-geo-integration/test_integration.py b/backend/schemas/ragflow-geo-integration/test_integration.py
new file mode 100644
index 0000000..78ee951
--- /dev/null
+++ b/backend/schemas/ragflow-geo-integration/test_integration.py
@@ -0,0 +1,243 @@
+"""
+RAGFlowä¸geoé¡¹ç›®é›†æˆæ¡†æ¶æµ‹è¯•è„šæœ¬
+ç”¨äºéªŒè¯é›†æˆæ¡†æ¶æ˜¯å¦èƒ½å¤Ÿæ­£å¸¸è¿è¡Œ
+"""
+import json
+import sys
+import os
+from unittest.mock import patch, MagicMock
+
+# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°ç³»ç»Ÿè·¯å¾„
+sys.path.insert(0, os.path.join(os.path.dirname(__file__)))
+
+from ragflow_integration import RAGFlowClient, GeoRAGFlowIntegration
+
+
+def test_ragflow_client_initialization():
+    """æµ‹è¯•RAGFlowClientåˆå§‹åŒ–"""
+    print("æµ‹è¯•1: RAGFlowClientåˆå§‹åŒ–...")
+    try:
+        client = RAGFlowClient("http://localhost:9380", "test_api_key")
+        assert client.base_url == "http://localhost:9380"
+        assert client.api_key == "test_api_key"
+        print("  âœ“ åˆå§‹åŒ–æˆåŠŸ")
+        return True
+    except Exception as e:
+        print(f"  âœ— åˆå§‹åŒ–å¤±è´¥: {e}")
+        return False
+
+
+def test_geo_ragflow_integration_initialization():
+    """æµ‹è¯•GeoRAGFlowIntegrationåˆå§‹åŒ–"""
+    print("æµ‹è¯•2: GeoRAGFlowIntegrationåˆå§‹åŒ–...")
+    try:
+        config = {
+            'base_url': 'http://localhost:9380',
+            'api_key': 'test_api_key',
+            'dataset_id': 'test_dataset_id'
+        }
+        integration = GeoRAGFlowIntegration(config)
+        assert integration.dataset_id == 'test_dataset_id'
+        print("  âœ“ åˆå§‹åŒ–æˆåŠŸ")
+        return True
+    except Exception as e:
+        print(f"  âœ— åˆå§‹åŒ–å¤±è´¥: {e}")
+        return False
+
+
+def test_headers_construction():
+    """æµ‹è¯•è¯·æ±‚å¤´æ„å»º"""
+    print("æµ‹è¯•3: è¯·æ±‚å¤´æ„å»º...")
+    try:
+        client = RAGFlowClient("http://localhost:9380", "test_api_key")
+        expected_headers = {
+            'Authorization': 'Bearer test_api_key',
+            'Content-Type': 'application/json'
+        }
+        assert client.headers == expected_headers
+        print("  âœ“ è¯·æ±‚å¤´æ„å»ºæ­£ç¡®")
+        return True
+    except Exception as e:
+        print(f"  âœ— è¯·æ±‚å¤´æ„å»ºå¤±è´¥: {e}")
+        return False
+
+
+def test_url_construction():
+    """æµ‹è¯•URLæ„å»º"""
+    print("æµ‹è¯•4: URLæ„å»º...")
+    try:
+        client = RAGFlowClient("http://localhost:9380", "test_api_key")
+        
+        # æµ‹è¯•åŸºç¡€URLå¤„ç†ï¼ˆå»é™¤æœ«å°¾æ–œæ ï¼‰
+        assert client.base_url == "http://localhost:9380"
+        
+        # æµ‹è¯•æœç´¢URLæ„å»º
+        search_url = f"{client.base_url}/api/v1/datasets/test_dataset_id/search"
+        expected_url = "http://localhost:9380/api/v1/datasets/test_dataset_id/search"
+        assert search_url == expected_url
+        
+        print("  âœ“ URLæ„å»ºæ­£ç¡®")
+        return True
+    except Exception as e:
+        print(f"  âœ— URLæ„å»ºå¤±è´¥: {e}")
+        return False
+
+
+def test_config_file():
+    """æµ‹è¯•é…ç½®æ–‡ä»¶æ ¼å¼"""
+    print("æµ‹è¯•5: é…ç½®æ–‡ä»¶æ ¼å¼...")
+    try:
+        with open('config_example.json', 'r', encoding='utf-8') as f:
+            config = json.load(f)
+        
+        required_keys = ['ragflow_config', 'search_params', 'connection']
+        for key in required_keys:
+            assert key in config, f"ç¼ºå°‘å¿…éœ€çš„é…ç½®é”®: {key}"
+        
+        ragflow_keys = ['base_url', 'api_key', 'dataset_id']
+        for key in ragflow_keys:
+            assert key in config['ragflow_config'], f"ç¼ºå°‘å¿…éœ€çš„RAGFlowé…ç½®é”®: {key}"
+        
+        print("  âœ“ é…ç½®æ–‡ä»¶æ ¼å¼æ­£ç¡®")
+        return True
+    except Exception as e:
+        print(f"  âœ— é…ç½®æ–‡ä»¶éªŒè¯å¤±è´¥: {e}")
+        return False
+
+
+def test_dependencies():
+    """æµ‹è¯•ä¾èµ–é¡¹"""
+    print("æµ‹è¯•6: ä¾èµ–é¡¹æ£€æŸ¥...")
+    try:
+        import requests
+        print(f"  âœ“ requestsç‰ˆæœ¬: {requests.__version__}")
+        return True
+    except ImportError as e:
+        print(f"  âœ— ä¾èµ–é¡¹å¯¼å…¥å¤±è´¥: {e}")
+        return False
+
+
+def run_mock_tests():
+    """è¿è¡Œæ¨¡æ‹Ÿæµ‹è¯•ï¼ˆæ¨¡æ‹ŸAPIè°ƒç”¨ï¼‰"""
+    print("æµ‹è¯•7: æ¨¡æ‹ŸAPIè°ƒç”¨...")
+    try:
+        # æ¨¡æ‹ŸAPIå“åº”
+        mock_response = {
+            'data': [
+                {
+                    'id': 'test_dataset',
+                    'name': 'Test Dataset',
+                    'status': 'ready'
+                }
+            ]
+        }
+        
+        # æ¨¡æ‹Ÿæœç´¢å“åº”
+        mock_search_response = {
+            'chunks': [
+                {
+                    'content': 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ç»“æœ',
+                    'score': 0.8,
+                    'doc_id': 'test_doc_1'
+                }
+            ]
+        }
+        
+        # åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹
+        client = RAGFlowClient("http://localhost:9380", "test_api_key")
+        
+        # ä½¿ç”¨mockæµ‹è¯•APIè°ƒç”¨
+        with patch('requests.get') as mock_get:
+            mock_get.return_value.status_code = 200
+            mock_get.return_value.json.return_value = mock_response
+            
+            # æµ‹è¯•è·å–æ•°æ®é›†åˆ—è¡¨
+            datasets = client.list_datasets()
+            assert len(datasets) == 1
+            assert datasets[0]['name'] == 'Test Dataset'
+        
+        with patch('requests.post') as mock_post:
+            mock_post.return_value.status_code = 200
+            mock_post.return_value.json.return_value = mock_search_response
+            
+            # æµ‹è¯•æœç´¢åŠŸèƒ½
+            search_results = client.search_in_dataset('test_dataset_id', 'test query')
+            assert 'chunks' in search_results
+        
+        print("  âœ“ æ¨¡æ‹ŸAPIè°ƒç”¨æˆåŠŸ")
+        return True
+    except Exception as e:
+        print(f"  âœ— æ¨¡æ‹ŸAPIè°ƒç”¨å¤±è´¥: {e}")
+        return False
+
+
+def test_integration_methods():
+    """æµ‹è¯•é›†æˆç±»æ–¹æ³•"""
+    print("æµ‹è¯•8: é›†æˆç±»æ–¹æ³•...")
+    try:
+        config = {
+            'base_url': 'http://localhost:9380',
+            'api_key': 'test_api_key',
+            'dataset_id': 'test_dataset_id'
+        }
+        integration = GeoRAGFlowIntegration(config)
+        
+        # æ£€æŸ¥å¿…éœ€çš„æ–¹æ³•æ˜¯å¦å­˜åœ¨
+        assert hasattr(integration, 'query_geospatial_knowledge')
+        assert hasattr(integration, 'get_knowledge_base_info')
+        assert hasattr(integration, '_process_search_results')
+        
+        # æµ‹è¯•ç»“æœå¤„ç†æ–¹æ³•
+        raw_results = {'chunks': [{'content': 'test content', 'score': 0.9, 'doc_id': 'doc1'}]}
+        processed = integration._process_search_results(raw_results)
+        assert len(processed) == 1
+        assert processed[0]['content'] == 'test content'
+        assert processed[0]['score'] == 0.9
+        assert processed[0]['source'] == 'doc1'
+        
+        print("  âœ“ é›†æˆç±»æ–¹æ³•æ­£å¸¸")
+        return True
+    except Exception as e:
+        print(f"  âœ— é›†æˆç±»æ–¹æ³•æµ‹è¯•å¤±è´¥: {e}")
+        return False
+
+
+def main():
+    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
+    print("å¼€å§‹æµ‹è¯•RAGFlowä¸geoé¡¹ç›®é›†æˆæ¡†æ¶...")
+    print("=" * 50)
+    
+    tests = [
+        test_ragflow_client_initialization,
+        test_geo_ragflow_integration_initialization,
+        test_headers_construction,
+        test_url_construction,
+        test_config_file,
+        test_dependencies,
+        run_mock_tests,
+        test_integration_methods
+    ]
+    
+    results = []
+    for test in tests:
+        result = test()
+        results.append(result)
+        print()
+    
+    print("=" * 50)
+    print(f"æµ‹è¯•å®Œæˆ! é€šè¿‡: {sum(results)}/8")
+    
+    if all(results):
+        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! é›†æˆæ¡†æ¶å¯ä»¥æ­£å¸¸è¿è¡Œã€‚")
+        print("\nè¦è¿›è¡Œå®é™…è¿æ¥æµ‹è¯•ï¼Œè¯·:")
+        print("1. ç¡®ä¿RAGFlowæœåŠ¡æ­£åœ¨è¿è¡Œ")
+        print("2. æ›´æ–°config_example.jsonä¸­çš„é…ç½®ä¿¡æ¯")
+        print("3. è¿è¡Œ: python test_connection.py")
+    else:
+        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç å’Œä¾èµ–é¡¹ã€‚")
+    
+    return all(results)
+
+
+if __name__ == "__main__":
+    main()